[{"date":"2022-12-04T10:45:00.000Z","url":"/2022/12/04/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","tags":[["设计模式","/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"],["单例模式","/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"]],"categories":[[" ",""]],"content":"#设计模式 #单例模式 一、什么是单例模式就如同他的名字一样，**’单例’**，就是只有一个实例。也就是说一个类在全局中最多只有一个实例存在，不能在多了，在多就不叫单例模式了。 单例模式（Singleton Pattern），它是 Java 中最简单的设计模式之一，属于创建型模式的一种，它提供了一种创建对象的最佳方式。 这种模式的意义在于保证一个类仅有一个实例，并提供一个访问它的全局访问点，避免重复的创建对象，节省系统资源。 二、实现思路1、实现思路创建一个类，将其默认构造方法私有化，使外界不能通过new Object来获取对象实例，同时提供一个对外获取对象唯一实例的方法。 2、用在哪里单例模式一般用在对实例数量有严格要求的地方，比如数据池，线程池，缓存，session回话等等。 3、在Java中构成的条件 静态变量 静态方法 私有构造器 二、单例模式的两种形态1、懒汉模式 这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。 线程不安全 2、饿汉模式 这种方式比较常用，但容易产生垃圾对象。优点：没有加锁，执行效率会提高。缺点：类加载时就初始化，浪费内存。它基于 classloader 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。 线程安全 三、懒汉模式优化成线程安全1、加synchronized关键字 此方法是最简单又有效的方法，不过对性能上会有所损失。比如两个线程同时调用这个实例，其中一个线程要等另一个线程调用完才可以继续调用。而线程不安全往往发生在这个实例在第一次调用的时候发生，当实例被调用一次后，线程是安全的，所以加synchronized就显得有些浪费性能。 2、用”双重检查加锁” 上个方法说到，线程不安全往往发生在这个实例在第一次调用的时候发生，当实例被调用一次后，线程是安全的。那有没有方法只有在第一次调用的时候才用synchronized关键字，而第一次后就不用synchronized关键字呢？答案是当然有的，就是用volatile来修饰静态变量，保持其可见性。 1、单重检查锁 2、双重检查锁 注意：在执行instance &#x3D; new Singleton();时，可能会出现CPU指令重排！ new 的过程会分为三个步骤： 1、在堆中开辟一块内存空间M； 2、根据Singleton类模板创建Singleton对象； 3、把Singleton对象赋值给instance。 理论上：1-&gt;2-&gt;3 实际上：1-&gt;3-&gt;2 3、volatile + 双重检查锁 3、用”静态内部类” 静态内部类的优点是：外部类加载时并不需要立即加载内部类，内部类不被加载则不去初始化INSTANCE，故而不占内存。即当SingleTon第一次被加载时，并不需要去加载SingleTonHoler，只有当getInstance()方法第一次被调用时，才会去初始化INSTANCE,第一次调用getInstance()方法会导致虚拟机加载SingleTonHoler类，这种方法不仅能确保线程安全，也能保证单例的唯一性，同时也延迟了单例的实例化。 4、枚举 这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。这种方式是 Effective Java 作者 Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还自动支持序列化机制，防止反序列化重新创建新的对象，绝对防止多次实例化。不过，由于 JDK1.5 之后才加入 enum 特性，用这种方式写不免让人感觉生疏，在实际工作中，也很少用。 四、应用单例模式在Java中的应用也很多，例如Runtime就是一个典型的例子，源码如下： 很清晰的看到，使用了饿汉式方式创建单例对象！ 五、总结 饿汉模式：性能好，写法简单，推荐使用； 加synchronized关键字：性能差，不过对懒汉模式比较直接有效； volatile-双重验证加锁：性能好，对Java版本有要求，要求Java5以上版本； 静态内部类：性能好，无需加锁，由JVM类加载保证。 枚举：还没被广泛采用，它更简洁，自动支持序列化机制，绝对防止多次实例化。 "},{"date":"2022-12-04T03:08:07.699Z","url":"/2022/12/04/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","categories":[[" ",""]],"content":"初级排序 - O(n^2)1、插入排序 将待排序数组分为已排序和未排序两个数组，每次从未排序数组中取一个值，插入有序数组中，此过程重复 n 次。 向有序数组中插入一个数：1、寻找插入位置；2、搬移数据。 性能分析： 时间复杂度：O(n^2) 空间复杂度：O(1) 稳定性：稳定 原地排序：是 代码实现： 二分插入 寻找插入位置时，使用二分查找 参考文档     成对插入 一次插入两个数 官方源码 代码实现 参考链接  希尔排序（Shellsort） 希尔排序（Shellsort），也称递减增量排序算法，是插入排序的一种更高效的改进版本。 希尔排序是基于插入排序的以下两点性质而提出改进方法的： 插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率 但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位 性能分析： 时间复杂度：根据步长序列的不同而不同！ 空间复杂度：O(1) 稳定性：不稳定 原地排序：是 代码实现： 2、选择排序 将待排序数组分为已排序和未排序两个数组，每次从未排序数组中选择一个最值，放入已排序数组的末尾，此过程重复 n 次。 性能分析： 时间复杂度：O(n^2) 空间复杂度：O(1) 稳定性：不稳定 举个例子，序列5 8 5 2 9， 我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了，所以选择排序不是一个稳定的排序算法。 原地排序：是 代码实现： 3、冒泡排序 对于待排序数组中的元素，从数组首部或尾部开始，元素之间两两进行比较，根据排序规则（从大到小&#x2F;从小到大），进行交换； 一趟下来，数组中的一个最值元素就被移动到了数组末尾或开头。 性能分析： 时间复杂度：O(n^2) 空间复杂度：O(1) 稳定性：稳定 原地排序：是 代码实现： 从前往后冒泡： 另一种形式： 从后往前冒泡： 优化： 继续优化： 另一种形式： 向下冒泡 高级排序 - O(nlogn)1、快速排序 优化一：单边递归 优化二：三点取中 2、归并排序二路归并： 特殊排序 - O(n)1、计数排序2、基数排序3、桶排序脑洞排序1、睡眠排序2、猴子排序3、珠排序4、面条排序Arrays.sort 源码分析 Dual-Pivot Quicksort 双轴快速排序 从 JDK 1.7 开始采用这种 Dual-Pivot Quicksort，首先会根据数组的长度选择对应的排序算法： 需要排序的数组为a，判断数组的长度是否大于&#x3D;&#x3D;286&#x3D;&#x3D;，大于使用Timesort 归并排序，否则执行2； 判断数组长度是否小于&#x3D;&#x3D;47&#x3D;&#x3D;，小于则采用插入排序，否则执行3； 双轴快排。 参考链接      "},{"date":"2022-12-04T03:08:07.699Z","url":"/2022/12/04/%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%8E%86%E9%99%A9%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E3%80%90Docker%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%E3%80%91/","categories":[[" ",""]],"content":"1、Docker为什么出现一款产品从开发到上线，从操作系统，到运行环境，再到应用配置。作为开发+运维之间的协作我们需要 关心很多东西，这也是很多互联网公司都不得不面对的问题，特别是各种版本的迭代之后，不同版本环境的兼容，对运维人员是极大的考验！ 环境配置如此麻烦，换一台机器，就要重来一次，费力费时。很多人想到，能不能从根本上解决问题， &#x3D;&#x3D;软件可以带环境安装？&#x3D;&#x3D;也就是说，安装的时候，把原始环境一模一样地复制过来。解决开发人员说的“ 在 我的机器上可正常工作”的问题。 之前在服务器配置一个应用的运行环境，要安装各种软件，就拿一个基本的工程项目的环境来说吧， Java&#x2F;Tomcat&#x2F;MySQL&#x2F;JDBC驱动包等。安装和配置这些东西有多麻烦就不说了，它还不能跨平台。假如 我们是在 Windows 上安装的这些环境，到了 Linux 又得重新装。况且就算不跨操作系统，换另一台同 样操作系统的服务器，要移植应用也是非常麻烦的。 传统上认为，软件编码开发&#x2F;测试结束后，所产出的成果即是程序或是能够编译执行的二进制字节码文件 等（Java为例）。而为了让这些程序可以顺利执行，开发团队也得准备完整的部署文件，让维运团队得 以部署应用程式，开发需要清楚的告诉运维部署团队，用的全部配置文件+所有软件环境。不过，即便如此，仍然常常发生部署失败的状况。 Docker之所以发展如此迅速，也是因为它对此给出了一个标准化的解决方案。 Docker镜像的设计，&#x3D;&#x3D;使得Docker得以打破过去「程序即应用」的观念。通过Docker镜像 ( images ) 将 应用程序所需要的系统环境，由下而上打包，达到应用程序跨平台间的无缝接轨运作。&#x3D;&#x3D; Docker的思想来自于集装箱，集装箱解决了什么问题？在一艘大船上，可以把货物规整的摆放起来。并 且各种各样的货物被集装箱标准化了，集装箱和集装箱之间不会互相影响。那么我就不需要专门运送水 果的船和专门运送化学品的船了。只要这些货物在集装箱里封装的好好的，那我就可以用一艘大船把他 们都运走。 Docker就是类似的理念。 历史 2010年，几个搞IT的年轻人，在美国旧金山成立了一家名叫“dotCloud”的公司。 这家公司主要提供基于PaaS的云计算技术服务。具体来说，是和LXC有关的容器技术。 后来，dotCloud公司将自己的容器技术进行了简化和标准化，并命名为——Docker。 Docker技术诞生之后，并没有引起行业的关注。而dotCloud公司，作为一家小型创业企业，在激烈的竞 争之下，也步履维艰。 正当他们快要坚持不下去的时候，脑子里蹦出了“开源”的想法。 什么是“开源”？开源，就是开放源代码。也就是将原来内部保密的程序源代码开放给所有人，然后让大 家一起参与进来，贡献代码和意见。 有的软件是一开始就开源的。也有的软件，是混不下去，创造者又不想放弃，所以选择开源。自己养不 活，就吃“百家饭”嘛。 2013年3月，dotCloud公司的创始人之一，Docker之父，28岁的Solomon Hykes正式决定，将 Docker项目开源。 不开则已，一开惊人。 越来越多的IT工程师发现了Docker的优点，然后蜂拥而至，加入Docker开源社区。 Docker的人气迅速攀升，速度之快，令人瞠目结舌。 开源当月，Docker 0.1 版本发布。此后的每一个月，Docker都会发布一个版本。到2014年6月9日， Docker 1.0 版本正式发布。 此时的Docker，已经成为行业里人气最火爆的开源技术，没有之一。甚至像Google、微软、Amazon、 VMware这样的巨头，都对它青睐有加，表示将全力支持。 Docker和容器技术为什么会这么火爆？说白了，就是因为它“轻”。 在容器技术之前，业界的网红是虚拟机。虚拟机技术的代表，是VMWare和OpenStack。 相信很多人都用过虚拟机。虚拟机，就是在你的操作系统里面，装一个软件，然后通过这个软件，再模拟一台甚至多台“子电脑”出来。 在“子电脑”里，你可以和正常电脑一样运行程序，例如开QQ。如果你愿意，你可以变出好几个“子电 脑”，里面都开上QQ。“子电脑”和“子电脑”之间，是相互隔离的，互不影响。 虚拟机属于虚拟化技术。而Docker这样的容器技术，也是虚拟化技术，属于轻量级的虚拟化。 虚拟机虽然可以隔离出很多“子电脑”，但占用空间更大，启动更慢，虚拟机软件可能还要花钱（例如 VMWare）。 而容器技术恰好没有这些缺点。它不需要虚拟出整个操作系统，只需要虚拟一个小规模的环境（类似“沙 箱”）。 它启动时间很快，几秒钟就能完成。而且，它对资源的利用率很高（一台主机可以同时运行几千个 Docker容器）。 此外，它占的空间很小，虚拟机一般要几GB到几十GB的空间，而容器只需要MB级甚至 KB级。 正因为如此，容器技术受到了热烈的欢迎和追捧，发展迅速。 总结： 2013~2014 年，以 Cloud Foundry 为代表的 PaaS 项目，逐渐完成了教育用户和开拓市场的艰巨任务，也正是在这个将概念逐渐落地的过程中，应用“打包”困难这个问题，成了整个后端技术圈子的一块心病。 Docker 项目的出现，则为这个根本性的问题提供了一个近乎完美的解决方案。这正是 Docker 项目刚刚开源不久，就能够带领一家原本默默无闻的 PaaS 创业公司脱颖而出，然后迅速占领了所有云计算领域头条的技术原因。 而在成为了基础设施领域近十年难得一见的技术明星之后，dotCloud 公司则在 2013 年底大胆改名为 Docker 公司。不过，这个在当时就颇具争议的改名举动，也成为了日后容器技术圈风云变幻的一个关键伏笔。 Docker 项目在短时间内迅速崛起的三个重要原因： Docker 镜像通过技术手段解决了 PaaS 的根本性问题； Docker 容器同开发者之间有着与生俱来的密切关系； PaaS 概念已经深入人心的完美契机。 Docker 理念 Docker是基于Go语言实现的云开源项目。 Docker的主要目标是“Build，Ship and Run Any App , Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“一次封装，到处运行”。 Linux 容器技术的出现就解决了这样一个问题，而 Docker 就是在它的基础上发展过来的。将应用运行在 Docker 容器上面，而 Docker 容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。只需 要一次配置好环境，换到别的机子上就可以一键部署好，大大简化了操作。 2、Docker能干嘛 之前的虚拟机技术 虚拟机（virtual machine）就是带环境安装的一种解决方案。 它可以在一种操作系统里面运行另一种操作系统，比如在Windows 系统里面运行Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。这类虚拟机完美的运行了另一套系统，能够使应用程序， 操作系统和硬件三者之间的逻辑不变。 虚拟机的缺点： 1、资源占用多 2、冗余步骤多 3 、启动慢 容器虚拟化技术 由于前面虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（Linux Containers，缩 写为 LXC）。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。有了容器，就可以将软件运行所需的所有资源打包到一个隔离的容器中。容器与虚拟机不同，不需要捆绑一整套操作系统，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一地运行。 比较了 Docker 和传统虚拟化方式的不同之处： 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用 进程； 而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。 因此容器要比传统虚拟机更为轻便。 每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。 开发&#x2F;运维（DevOps） 更快速的应用交付和部署： 传统的应用开发完成后，需要提供一堆安装程序和配置说明文档，安装部署后需根据配置文档进行繁杂 的配置才能正常运行。Docker化之后只需要交付少量容器镜像文件，在正式生产环境加载镜像并运行即可，应用安装配置在镜像里已经内置好，大大节省部署配置和测试验证时间。 更便捷的升级和扩缩容： 随着微服务架构和Docker的发展，大量的应用会通过微服务方式架构，应用的开发构建将变成搭乐高积 木一样，每个Docker容器将变成一块“积木”，应用的升级将变得非常容易。当现有的容器不足以支撑业务处理时，可通过镜像运行新的容器进行快速扩容，使应用系统的扩容从原先的天级变成分钟级甚至秒级。 更简单的系统运维： 应用容器化运行后，生产环境运行的应用可与开发、测试环境的应用高度一致，容器会将应用程序相关的环境和状态完全封装起来，不会因为底层基础架构和操作系统的不一致性给应用带来影响，产生新的 BUG。当出现程序异常时，也可以通过测试环境的相同容器进行快速定位和修复。 更高效的计算资源利用： Docker是内核级虚拟化，其不像传统的虚拟化技术一样需要额外的Hypervisor [管理程序] 支持，所以在 一台物理机上可以运行很多个容器实例，可大大提升物理服务器的CPU和内存的利用率。 学习途径 Docker官网： Docker中文网站： Docker Hub官网： （仓库）"},{"date":"2022-12-04T03:08:07.699Z","url":"/2022/12/04/%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%8E%86%E9%99%A9%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E3%80%90Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E3%80%91/","categories":[[" ",""]],"content":"[TOC] Docker 常用命令帮助命令 镜像命令 容器命令 说明：有了镜像才可以创建容器！我们下载一个 CentOS 镜像来测试学习！ docker pull centos 常用的其他命令后台启动容器 进入当前正在运行的容器 从容器内拷贝文件到主机上 命令小结 Docker 安装 Nginx 思考问题：我们每次改动 nginx 配置文件，都需要进入容器内部？十分麻烦，要是可以在容器外部提供一个映射路径，达到在容器修改文件，容器内部就可以自动修改？ -v 数据卷技术 Docker 安装 Tomact 发现Linux命令少了，并且webapps里面没有文件！ 原因：阿里云镜像的原因，默认是最小的镜像，所有不必要的都剔除了！保证最小可运行的环境！ 把webapps里的文件拷贝到webapp下，再次访问测试！ 思考问题：我们以后要部署项目，如果每次都要进入容器是不是十分麻烦？我们要是可以在容器外部提供一个映射路径，webapps，我们在外部放置项目，就自动同步到容器内部！ "},{"date":"2022-12-04T03:08:07.699Z","url":"/2022/12/04/%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%8E%86%E9%99%A9%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E3%80%90Docker%E5%AE%89%E8%A3%85%E3%80%91/","categories":[[" ",""]],"content":"1、Docker的基本组成Docker的架构图： 镜像（image）： 容器（container）： 仓库（repository）： 小结： 需要正确的理解仓储&#x2F;镜像&#x2F;容器这几个概念 : Docker 本身是一个容器运行载体或称之为管理引擎。我们把应用程序和配置依赖打包好形成一个 可交付的运行环境，这个打包好的运行环境就似乎 image镜像文件。只有通过这个镜像文件才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。 同一个 image 文件，可以生成多个同时运行的容器实例。 image 文件生成的容器实例，本身也是一个文件，称为镜像文件。 一个容器运行一种服务，当我们需要的时候，就可以通过docker客户端创建一个对应的运行实例， 也就是我们的容器。 至于仓库，就是放了一堆镜像的地方，我们可以把镜像发布到仓库中，需要的时候从仓库中拉下来 就可以了。 2、环境说明我们使用的是 CentOS 7 (64-bit) 目前，CentOS 仅发行版本中的内核支持 Docker。 Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。 查看自己的内核： uname -r 命令用于打印当前系统相关信息（内核版本号、硬件架构、主机名称和操作系统类型 等）。 查看版本信息： cat /etc/os-release 3、安装步骤1、官网安装参考手册： 2、确定你是CentOS7及以上版本，我们已经做过了 3、yum安装gcc相关环境（需要确保 虚拟机可以上外网 ） 4、卸载旧版本 5、安装需要的软件包 6、设置镜像仓库 7、更新yum软件包索引 8、安装 Docker CE 9、启动 Docker 10、测试命令 11、卸载 4、阿里云镜像加速1、介绍： 2、注册一个属于自己的阿里云账户(可复用淘宝账号) 3、进入管理控制台设置密码，开通 4、查看镜像加速器自己的 5、配置镜像加速 测试 HelloWorld 1、启动hello-world 2、run干了什么？ 5、底层原理Docker是怎么工作的 Docker是一个Client-Server结构的系统，Docker守护进程运行在主机上， 然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。 容器，是一个运行时环境，就是我们前面说到的集装箱。 为什么Docker比较 VM 快 1、docker有着比虚拟机更少的抽象层。由于docker不需要Hypervisor实现硬件资源虚拟化，运行在 docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有明显优势。 2、docker利用的是宿主机的内核，而不需要Guest OS。因此,当新建一个容器时,docker不需要和虚拟机 一样重新加载一个操作系统内核。仍而避免引寻、加载操作系统内核返个比较费时费资源的过程,当新建 一个虚拟机时,虚拟机软件需要加载Guest OS,返个新建过程是分钟级别的。而docker由于直接利用宿主 机的操作系统,则省略了返个过程,因此新建一个docker容器只需要几秒钟。 "},{"date":"2022-12-04T03:08:07.699Z","url":"/2022/12/04/%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%8E%86%E9%99%A9%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89%E3%80%90%E5%AE%B9%E5%99%A8%E6%95%B0%E6%8D%AE%E5%8D%B7%E3%80%91/","categories":[[" ",""]],"content":"1、什么是容器数据卷docker的理念回顾： 将应用和运行的环境打包形成容器运行，运行可以伴随着容器，但是我们对于数据的要求，是希望能够 持久化的！ 就好比，你安装一个MySQL，结果你把容器删了，就相当于删库跑路了，这TM也太扯了吧！ 所以我们希望容器之间有可能可以共享数据，Docker容器产生的数据，如果不通过docker commit 生成 新的镜像，使得数据作为镜像的一部分保存下来，那么当容器删除后，数据自然也就没有了！这样是行不通的！ 为了能保存数据在Docker中我们就可以使用卷！让数据挂载到我们本地！这样数据就不会因为容器删除 而丢失了！ 作用： 卷就是目录或者文件，存在一个或者多个容器中，由docker挂载到容器，但不属于联合文件系统，因此 能够绕过 Union File System ， 提供一些用于持续存储或共享数据的特性。 卷的设计目的就是数据的持久化，完全独立于容器的生存周期，因此Docker不会在容器删除时删除其挂载的数据卷。 特点： 1、数据卷可在容器之间共享或重用数据 2、卷中的更改可以直接生效 3、数据卷中的更改不会包含在镜像的更新中 4、数据卷的生命周期一直持续到没有容器使用它为止 所以：总结一句话： 就是容器的持久化，以及容器间的继承和数据共享！ 2、使用数据卷 方式一：容器中直接使用命令来添加 挂载 查看数据卷是否挂载成功 docker inspect 容器id 测试容器和宿主机之间数据共享：可以发现，在容器中，创建的会在宿主机中看到！ 测试容器停止退出后，主机修改数据是否会同步！ 停止容器 在宿主机上修改文件，增加些内容 启动刚才停止的容器 然后查看对应的文件，发现数据依旧同步！ok 使用 Docker 安装 MySQL 思考：mysql 数据持久化的问题！ 通过Docker File 来添加（了解） DockerFile 是用来构建Docker镜像的构建文件，是由一些列命令和参数构成的脚本。 我们在这里，先体验下，后面我们会详细讲解 DockerFile ！ 注意：如果访问出现了 cannot open directory: Permission denied 解决办法：在挂载目录后多加一个 --privileged=true 参数即可 3、匿名和具名挂载 4、数据卷容器命名的容器挂载数据卷，其他容器通过挂载这个（父容器）实现数据共享，挂载数据卷的容器，称之为 数据卷容器。 我们使用上一步的镜像：ziyang&#x2F;centos 为模板，运行容器 docker01，docker02，docker03，他们都会具有容器卷： 我们来测试下，容器间传递共享 1、先启动一个父容器docker01，然后在volume02新增文件； 退出不停止：ctrl+P+Q； 2、创建docker02，docker03 让他们继承docker01 --volumes-from 3、回到docker01发现可以看到 02 和 03 添加的共享文件； 4、删除docker01，docker02 修改后docker03还能不能访问？ 5、删除docker02 ，docker03还能不能访问？ 6、新建docker04继承docker03，然后再删除docker03，看下是否可以访问？ 得出结论： 容器之间配置信息的传递，数据卷的生命周期一直持续到没有容器使用它为止。 存储在本机的文件则会一直保留！"},{"date":"2022-12-04T03:08:07.699Z","url":"/2022/12/04/%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%8E%86%E9%99%A9%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%E3%80%90DockerFile%E3%80%91/","categories":[[" ",""]],"content":"DockerFile大家想想，Nginx，tomcat，mysql 这些镜像都是哪里来的？官方能写，我们不能写吗？ 我们要研究自己如何做一个镜像，而且我们写的微服务项目以及springboot打包上云部署，Docker就是 最方便的。 微服务打包成镜像，任何装了Docker的地方，都可以下载使用，极其的方便。 流程：开发应用&#x3D;&gt;DockerFile&#x3D;&gt;打包为镜像&#x3D;&gt;上传到仓库（私有仓库，公有仓库）&#x3D;&gt; 下载镜像 &#x3D;&gt; 启动运行。 还可以方便移植！ 什么是DockerFiledockerfile是用来构建Docker镜像的构建文件，是由一系列命令和参数构成的脚本。 构建步骤： 1、编写DockerFile文件 2、docker build 构建镜像 3、docker run dockerfile文件我们刚才已经编写过了一次，这里我们继续使用 centos 来看！ 地址： DockerFile构建过程基础知识： 1、每条保留字指令都必须为大写字母且后面要跟随至少一个参数 2、指令按照从上到下，顺序执行 3、# 表示注释 4、每条指令都会创建一个新的镜像层，并对镜像进行提交 流程： 1、docker从基础镜像运行一个容器 2、执行一条指令并对容器做出修改 3、执行类似 docker commit 的操作提交一个新的镜像层 4、Docker再基于刚提交的镜像运行一个新容器 5、执行dockerfile中的下一条指令直到所有指令都执行完成！ 说明： 从应用软件的角度来看，DockerFile，docker镜像与docker容器分别代表软件的三个不同阶段。 DockerFile 是软件的原材料 （代码） Docker 镜像则是软件的交付品 （.apk） Docker 容器则是软件的运行状态 （客户下载安装执行） DockerFile 面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可！ DockerFile：需要定义一个DockerFile，DockerFile定义了进程需要的一切东西。DockerFile涉及的内容 包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程（当引用进行需要和系统服务和内核进程打交道，这时需要考虑如何设计 namespace的权限控制）等等。 Docker镜像：在DockerFile 定义了一个文件之后，Docker build 时会产生一个Docker镜像，当运行 Docker 镜像时，会真正开始提供服务； Docker容器：容器是直接提供服务的。 DockerFile指令关键字： 实战测试Docker Hub 中99% 的镜像都是通过在base镜像（Scratch）中安装和配置需要的软件构建出来的 自定义一个 centos 1、编写DockerFile 查看下官方默认的CentOS的情况："},{"date":"2022-12-04T03:08:07.699Z","url":"/2022/12/04/%E5%B0%8F%E9%B2%B8%E9%B1%BC%E5%8E%86%E9%99%A9%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89%E3%80%90Docker%E9%95%9C%E5%83%8F%E3%80%91/","categories":[[" ",""]],"content":"1、镜像是什么镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。 2、Docker镜像加载原理 UnionFS （联合文件系统） UnionFS（联合文件系统）：Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统， 它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系 统下(unite several directories into a single virtual filesystem)。Union 文件系统是 Docker 镜像的基 础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件 系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。 Docker镜像加载原理 Docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。 bootfs(boot file system)主要包含bootloader和kernel, bootloader主要是引导加载kernel, Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs。这一层与我们典型的Linux&#x2F;Unix系统是 一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。 rootfs (root file system) ，在bootfs之上。包含的就是典型 Linux 系统中的 &#x2F;dev, &#x2F;proc, &#x2F;bin, &#x2F;etc 等标 准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。 平时我们安装进虚拟机的CentOS都是好几个G，为什么Docker这里才200M？ 对于一个精简的OS，rootfs 可以很小，只需要包含最基本的命令，工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就可以了。由此可见对于不同的linux发行版, bootfs基本是一 致的, rootfs会有差别, 因此不同的发行版可以公用bootfs。 3、分层理解 分层的镜像 我们可以去下载一个镜像，注意观察下载的日志输出，可以看到是一层一层的在下载！ 思考：为什么Docker镜像要采用这种分层的结构呢？ 最大的好处，我觉得莫过于是资源共享了！比如有多个镜像都从相同的Base镜像构建而来，那么宿主机只需在磁盘上保留一份base镜像，同时内存中也只需要加载一份base镜像，这样就可以为所有的容器服 务了，而且镜像的每一层都可以被共享。 查看镜像分层的方式可以通过 docker image inspect 命令！ 理解： 所有的 Docker 镜像都起始于一个基础镜像层，当进行修改或增加新的内容时，就会在当前镜像层之 上，创建新的镜像层。 举一个简单的例子，假如基于 Ubuntu Linux 16.04 创建一个新的镜像，这就是新镜像的第一层；如果在该镜像中添加 Python包，就会在基础镜像层之上创建第二个镜像层；如果继续添加一个安全补丁，就会创建第三个镜像层。 该镜像当前已经包含 3 个镜像层，如下图所示（这只是一个用于演示的很简单的例子）。 在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。下图中举了 一个简单的例子，每个镜像层包含 3 个文件，而镜像包含了来自两个镜像层的 6 个文件。 上图中的镜像层跟之前图中的略有区别，主要目的是便于展示文件。 下图中展示了一个稍微复杂的三层镜像，在外部看来整个镜像只有 6 个文件，这是因为最上层中的文件 7 是文件 5 的一个更新版本。 这种情况下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像当中。 Docker 通过存储引擎（新版本采用快照机制）的方式来实现镜像层堆栈，并保证多镜像层对外展示为统 一的文件系统。 Linux 上可用的存储引擎有 AUFS、Overlay2、Device Mapper、Btrfs 以及 ZFS。顾名思义，每种存储引擎都基于 Linux 中对应的文件系统或者块设备技术，并且每种存储引擎都有其独有的性能特点。 Docker 在 Windows 上仅支持 windowsfilter 一种存储引擎，该引擎基于 NTFS 文件系统之上实现了分层和 CoW[1]。 下图展示了与系统显示相同的三层镜像。所有镜像层堆叠并合并，对外提供统一的视图。 特点 Docker镜像都是只读的，当容器启动时，一个新的可写层被加载到镜像的顶部！ 这一层就是我们通常说的容器层，容器之下的都叫镜像层！ 4、镜像Commitdocker commit 从容器创建一个新的镜像。 测试 "},{"date":"2022-12-04T03:08:07.699Z","url":"/2022/12/04/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3HashMap%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/","categories":[[" ",""]],"content":"[toc] 基本概念HashMap类主要用来处理具有键值对特征的数据。随着JDK版本的更新，JDK 1.8 对HashMap底层进行了优化。 HashMap是基于哈希表对Map接口的实现，HashMap具有较快的访问速度，但是遍历顺序却是不确定的。 HashMap提供所有可选的映射操作，并允许使用 null值 和 null键。 Hash并非线程安全，当存在多个线程同时写入HashMap时，可能会导致数据的不一致。 必知字段 loadFactor 称为负载因子，默认值为0.75 threshold 表示所能容纳的键值对的临界值 threshold 计算公式为：数组长 * 负载因子 size 是HashMap中实际存在的键值对数量 modCount 字段用来记录HashMap内部结构发生变化的次数 HashMap的默认容量 INITIAL_CAPACITY 为16 存储结构在JDK 1.8 中，HashMap 采用了数组 + 链表 + 红黑树的存储结构。 HashMap数组部分称为哈希桶，当链表长度大于等于&#96;&#96; 8 时，链表数据将以 红黑树 的形式进行存储，当长度降到 6 时，转为 链表。 链表的时间复杂度为O(n)； 红黑树的时间复杂度为O(logn)； 每个Node节点存储着用来定位数据索引位置的hash值，k键，v值以及指向链表下一个节点的 Node&lt;K, V&gt; next 节点组成。 Node 是 HashMap的内部类，实现了Map.Entry接口，本质是一个键值对。 当向 HashMap 中插入数据时，首先要确定在哈希桶中的位置，那么如何确定Node的存储位置呢？ 以添加key键为字符 ‘e’ 为例： HashMap首先调用 hashCode() 方法，获取键key的hashCode值 h(101)，然后对其进行高位运算： 将 h 右移16位以取得h的 高16位，与原 h 的 低16位 进行异或运算（结果为 101） 最后将得到的 h值 与（table.length - 1）进行与运算获得该对象的 保留位 以计算下标。 例如存放键key分别为 ‘a’, ‘b’, ‘c’, ‘d’, ‘r’, ‘t’, ‘e’, ‘a’, ‘g’, ‘i’ 对象， 通过计算知： ‘a’ 的下标为 1(0001) ‘b’ 为 2(0010), ‘d’ 为 4(0100), ‘r’ 为 2(0010), ‘t’ 为 4(0100), ‘e’ 为 5(0101) 当HashMap调用 put() 方法插入键为字符的对象时： HashMap键的输出顺序为：a, b, r, d, t, e, g, i 当插入第二个以’a’为key的对象时，将新值赋值给’a’的值； 当插入的对象大小超过临界值时，HashMap将新建一个桶数组，并重新赋值（jdk1.7 和 jdk1.8 重新赋值方式略有不同） HashMap键的输出顺序为：null, a, b, d, e, f, g, i, j, k, r, t, u, w 面试常问面试官：在日常开发中，JDK 中包含的集合几乎我们每天都会用到，那么你可以简单地说一下Java的集合容器包含了哪些吗？【Java集合容器包含了哪些？】 答：主要是三个接口：List、Set、Map，以及实现了这些接口的诸多子类。 面试官：那他们三个都是对Collection接口的实现吗？ 答：不是的，List、Set是实现了Collection接口，Map是单独的接口，只不过当我们在谈到这个JDK的容器的时候，经常会把这三者放在一起谈。 面试官：你能简单说说这三者在概念上的差别吗？【List、Set、Map的基本区别】 答：List是有序的，这个有序指的是插入元素的顺序，其中呢可以存放重复的值和null值；Set呢它是无序的，其中的值是各不相同的，所以呢它里面只能存放一个null值；Map呢它存放的是Entry键值对，键呢必须是唯一的，所以说在Map里面只能存放一个键为null的值，但是可以存放多个值为null的Entry。 面试官：在Map中最常用的要数HashMap，关于HashMap，你能说说你的理解吗？【HashMap的基本概念】 答：关于HashMap，正如它的名字那样，它的key是通过hashCode来进行存储的，这又要谈到它的内部结构了，HashMap内部的数据结构呢主要用到了三种，一种就是数组，然后是链表，以及在JDK8中为了提升它的查询速度呢，加入的红黑树结构。 面试官：你可以具体的讲一下吗？ 答：可以看我画的这张图更加直观一些。我来介绍一下HashMap中的数据结构，首先呢HashMap维护了一个数组，数组中存储的元素类型为Entry，Entry就是键值对，当每一个Entry要被添加到Map中时，首先要使用Hash算法来计算它的hashCode【计算的是key的hashCode】，然后对hashCode进行取模操作，比如entryA取到的模是1，entryB取到的是0，entryC取到的是3，那么根据这个值来添加到对应的数组中的位置，这样呢就不难发现，添加的过程中hash算法是比较重要的，加入一个Hash算法比较优秀的话呢，它计算出来的hashCode是比较分散比较均匀的，所以每一个元素都能均匀地分布在数组中，这样的呢，就认为这个hash算法是优秀的，然后它的查找时间复杂度就是O(1)，如果这个Hash算法比较差呢，那么它可能计算出来的hashCode取模的结果都是一样的，那么整个数组就会退化成一个链表，那么它的查询速度就会变成O(n)，这样的话它们的查询效率差异将会是非常大的。JDK 1.8 中对此做了一些优化，就是说当一个数组的节点上挂载的node的数值超过8时，就将这个链表转化成红黑树，那红黑树的查询速度是O(logn)，这样呢就起到了一定的优化作用。 面试官：那为什么这个临界值设置为8呢？ 答：至于这个临界值为什么是8呢，这个是和泊松分布有关的，为什么这么设计呢？这也是类库的开发者在性能和空间开销上的一个取舍。 面试官：看过具体的源码吗？说说它的实现方式吧。【HashMap中的元素Node的源码分析】 答：之前提到了HashMap的数据结构是 数组 + 链表，其中数组中存储的元素叫Node，那么我们就来说一下Node吧！ Node是对Entry的一个实现，Entry是一个接口，Node是它的一个实现类，那我们接下来再看一下Node的源码！ 那我们可以看到 Node实现了 Entry这个接口，再来看看它的属性值，一个是hash，hash就是记录它的hash值，除了key和value呢，还有一个next，next就指向这个node的下一个节点，因为它的可以被拓展成一个链表的，接下来呢我们再看看它的方法，除了getter、setter方法，我们可以看到Node重写了Object的hashCode和equals方法。 明白了Node的构成之后呢，我们再来看一下HashMap的成员属性。 从它的源码可以来看一看，除了我们之前提到的 table，它是一个node数组之外呢，还有 entrySet，size，modCount，threshold，loadFactor 这几个属性。 一一来解释下，可以看到这个Set的泛型是 Map.Entry，它是Node的一个上层接口，主要存放Map中所有的Entry，便于用来进行遍历等操作； size 是 table 中被使用的实际元素的数量； modCount 是一个计数器，它主要用来记录HashMap结构发生变化的次数，比如put了一个新的key，发生了扩容等等； threshold &#x3D; size * loadFactor； loadFactor 是负载因子，在下面扩容机制的时候会详细介绍这个属性的作用。默认值它是 0.75。 面试官：不好意思，打断一下，transient 这个修饰符不是很常见，你能介绍一下它的作用吗？【笔记5：transient修饰符的作用】 答：transient 到底是干什么用的呢，是这样子的，Java中有个Serilizable 接口，就是当一个类实现了这个接口之后，它就能进行自动序列化，那么什么是自动的序列化呢？就是说Java进程之间在进行对象传输的时候，或者说对对象进行持久化等操作的时候呢，就要将这个对象序列化成二进制流，然后便于传输或者进行存储。那transient 修饰了一个属性之后呢，该属性将不会被自动序列化，比如一些敏感的字段，类库开发者是不希望它被序列化的。 比如说有一个对象它有一个private的属性int是a，然后它还有一个transient的int类型的属性b，那么它序列化之后保存到本地文件上，之后再进行序列化成对象的时候，这个属性b将会消失，因为它是不可见的。 面试官：好的，你说的没错，那么接下来我们再回归正题吧，我们知道table是一个数组，数组是在初始化指定长度的，无法动态扩展，但是呢在实际业务中我们往往无法预测它的未来长度，那么这点HashMap是如何解决的呢？【笔记6：核心重点：HashMap扩容机制】 答：接下来我就结合上述几个属性来介绍一下HashMap比较核心的扩容机制吧，首先谈谈扩容的时机，就是HashMap在什么情况下才会扩容。 从源码中这两行我们可以得知，HashMap默认初始化长度是16，它的默认负载因子是0.75，那么负载因子是用来干嘛的呢？ 当table中的元素被使用到了75%以上的时候呢，将会进行扩容，那么threshold指的就是这样一个临界值，它等于 size * loadFactor。 当table中元素个数达到这个threshold 之后将会进行扩容，每次扩容都是成倍的，即扩容之后table大小是之前的两倍，扩容属于一个比较消耗资源的操作，它需要为数组分配更多的空间。但是呢，它的好处就是说，因为你的数组更长了，所以hash算法的结果能够更均匀，它的碰撞也会更少，那么个数与碰撞的几率是服从泊松分布的，就是发现在0.75处碰撞的几率是最小的，所以使用0.75作为默认的负载因子。当然，如果面临特殊的业务情况下，开发者是可以手动控制负载因子的，HashMap也提供了相应的构造器。 面试官：那么你能谈一谈负载因子的默认值为什么是0.75，而它扩容的时候又是成倍增加的呢？你能去揣测一下开发者他为什么这么设计吗？【笔记7：为什么HashMap扩容，每次长度都是 * 2】 答：至于为什么table的长度一定是2的次幂，是为了在取模的时候做优化，当判断一个元素进入哪一个桶的时候，需要对key的hash值进行取模（%），但是 % 是一个比较重的操作，它比较耗性能，而当数组的长度总是2的n次方时，h &amp; (length - 1) 运算等价于对 length 取模（下面会讲到），相较于 %，&amp; 操作性能更好。 为什么呢？因为它是位运算操作，直接对二进制数据计算，而 % 需要将hash值转化为十进制后再计算。所以 &amp; 在性能上有很大优势，可以看一下下面两段代码： 可以看到，Node中的hash属性都是通过上面的hash函数计算出来的，那么为什么在计算key的hash值的时候，为什么要将key的hash值右移16位，然后再进行异或操作？ 这其实也是HashMap设计中的一个细节，在扩容时，将旧 old table 中的元素添加到 new table 时，使用了 newTab[e.hash &amp; (newCap - 1)] = e; 这样的操作. 面试官：上面你聊到了hash算法的源码，那么能介绍一下，为什么HashMap要在Object的hashCode的基础上，进行异或和右移的操作呢 (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); ，这样有什么好处？【笔记8：在取模之前，进行右移和异或的好处】 答：将key的hash值无符号右移16位，然后再与旧值进行异或操作，主要是为了保留高位和低位的信息，这样就能够表现目标值的特征，这样能够减少碰撞。 假如A的值是 11101110，当它与 111 进行 &amp; 运算的时候，它的高四位的信息将会全部丢失，因为 &amp; 111 的高四位全都是0，所以得出的结果就是 110。 异或（^）相同取0，不同取1&amp;：全1才1 那么我们首先对 A 进行右移四位的操作之后呢，将会得到 00001110 这个值，然后再将旧的值和新的值进行异或操作之后呢，将会得到 11101110，再用这个值与 (length - 1) 进行&amp; 操作之后呢，我们会发现得到了一个不一样的结果：00000000，这个结果作为A的模就更加具有代表性，因为它混合了A的高四位和低四位之间的信息。 面试官：那你能解释下为什么“当数组的length总是2的n次方时，h &amp; (length - 1)运算等价于对length取模”呢？【笔记9：为什么 h % length &#x3D;&#x3D; h &amp; (length - 1)】 答：为什么length对hash值取模的结果和 hash值对(length - 1) 做 &amp; 之后的结果是一样的呢，那首先我们需要知道一个概念，对无符号数取模和取余是一样的，设length 为 2^n，那么hash值对2^n取余，就是将x的二进制表示右移n位，结果就是商，移动的n位则是余数，当 length 为 2^n，则 2 ^(n - 1) 的二进制表示等于 n 个 1，与之做与操作，结果是一样的。 我们假设这个hash值是：1101 1101（221），10（2），可以计算得出它的取模结果是 1。 我们将这个hash值的二进制表示右移n位，移动的其实就是最后两位 01（1），01就是余数，01的十进制表示就是1，这和我们刚才计算得出的1是一致的。 那么我们在用hash对(length - 1)进行&amp;操作：10 - 1 其实就是十进制的 2- 1，得出的二进制结果是01，那么我们对 11011101 与 01 做 &amp; 操作，得出的结果也是01，那么它的十进制表示也是1。 面试官：那么接下来你可以说一下，一个元素put的整个流程吗？【笔记10：put操作的流程】 在这张图中最重要的是我们需要知道如果table为空，或是length为0，那么HashTable将会扩容，其他的情况实在插入之后再进行扩容。 面试官：那么关于HashMap的最后一个重点，可以介绍一下它的线程安全情况吗？【笔记11：HashMap线程不安全】 答：首先先说结论：HashMap不是线程安全的，因为我们看它的源码可以知道，它的很多操作都不是使用 synchronized 来进行同步的。 首先呢我们来看它的resize这个源码，resize逻辑很简单，其实就是将旧数组中的元素通过转换之后将其填充到新数组之中，那么关键就是这个transfer这个函数方法. 刚才也提到了transfer函数主要是将旧数组中的元素填充到新数组中去，那么我们这边假设一个旧数组的长度是2，它扩容之后的数组长度是4。 HashMap在扩容的时候是如何产生线程安全问题的，假设我们有两个线程thread1和thread2，首先我们需要明确几个概念，newTable这些变量都是在当前线程栈中的，所以它是跟线程无关的，它是线程独立的，但是node这些节点是在堆内存中分配的，不同的线程是可以对它进行操作，那么就会存在线程同步问题。 JDK 1.7中是 头插法 "},{"date":"2022-12-04T03:08:07.695Z","url":"/2022/12/04/Java%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/","categories":[[" ",""]],"content":"Java 基础1、谈谈你对 Java 平台的理解？“Java 是解释执行”，这句话正确吗？Java 本身是一种面向对象的语言，最显著的特性有两个方面，一是所谓的“书写一次，到处运行”（Write once, run anywhere），能够非常容易地获得跨平台能力；另外就是垃圾收集（GC, Garbage Collection），Java 通过垃圾收集器（Garbage Collector）回收分配内存，大部分情况下，程序员不需要自己操心内存的分配和回收。 我们日常会接触到 JRE（Java Runtime Environment）或者 JDK（Java Development Kit）。 JRE，也就是 Java 运行环境，包含了 JVM 和 Java 类库，以及一些模块等。而 JDK 可以看作是 JRE 的一个超集，提供了更多工具，比如编译器、各种诊断工具等。 对于“Java 是解释执行”这句话，这个说法不太准确。我们开发的 Java 的源代码，首先通过 Javac 编译成为字节码（bytecode），然后，在运行时，通过 Java 虚拟机（JVM）内嵌的解释器将字节码转换成为最终的机器码。但是常见的 JVM，比如我们大多数情况使用的 Oracle JDK 提供的 Hotspot JVM，都提供了 JIT（Just-In-Time）编译器，也就是通常所说的动态编译器，JIT 能够在运行时将热点代码编译成机器码，这种情况下部分热点代码就属于编译执行，而不是解释执行了。 2、请对比 Exception 和 Error，另外，运行时异常与一般异常有什么区别？Exception 和 Error 都是继承了 Throwable 类，在 Java 中只有 Throwable 类型的实例才可以被抛出（throw）或者捕获（catch），它是异常处理机制的基本组成类型。 Exception 和 Error 体现了 Java 平台设计者对不同异常情况的分类。Exception 是程序正常运行中，可以预料的意外情况，可能并且应该被捕获，进行相应处理。 Error 是指在正常情况下，不大可能出现的情况，绝大部分的 Error 都会导致程序（比如 JVM 自身）处于非正常的、不可恢复状态。既然是非正常情况，所以不便于也不需要捕获，常见的比如 OutOfMemoryError 之类，都是 Error 的子类。 Exception 又分为可检查（checked）异常和不检查（unchecked）异常，可检查异常在源代码里必须显式地进行捕获处理，这是编译期检查的一部分。前面我介绍的不可查的 Error，是 Throwable 不是 Exception。 不检查异常就是所谓的运行时异常，类似 NullPointerException、ArrayIndexOutOfBoundsException 之类，通常是可以编码避免的逻辑错误，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。 3、谈谈 final、finally、 finalize 有什么不同？final 可以用来修饰类、方法、变量，分别有不同的意义，final 修饰的 class 代表不可以继承扩展，final 的变量是不可以修改的，而 final 的方法也是不可以重写的（override）。 finally 则是 Java 保证重点代码一定要被执行的一种机制。我们可以使用 try-finally 或者 try-catch-finally 来进行类似关闭 JDBC 连接、保证 unlock 锁等动作。 finalize 是基础类 java.lang.Object 的一个方法，它的设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize 机制现在已经不推荐使用，并且在 JDK 9 开始被标记为 deprecated。 4、强引用、软引用、弱引用、幻象引用有什么区别？具体使用场景是什么？不同的引用类型，主要体现的是对象不同的可达性（reachable）状态和对垃圾收集的影响。 所谓强引用（“Strong” Reference），就是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾收集器不会碰这种对象。对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，就是可以被垃圾收集的了，当然具体回收时机还是要看垃圾收集策略。 软引用（SoftReference），是一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集，只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象。JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 弱引用（WeakReference）并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。这就可以用来构建一种没有特定约束的关系，比如，维护一种非强制性的映射关系，如果试图获取时对象还在，就使用它，否则重现实例化。它同样是很多缓存实现的选择。 对于幻象引用，有时候也翻译成虚引用，你不能通过它访问对象。幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制，比如，通常用来做所谓的 Post-Mortem 清理机制，我在专栏上一讲中介绍的 Java 平台自身 Cleaner 机制等，也有人利用幻象引用监控对象的创建和销毁。 5、理解 Java 的字符串，String、StringBuffer、StringBuilder 有什么区别？String 是 Java 语言非常基础和重要的类，提供了构造和管理字符串的各种基本逻辑。它是典型的 Immutable 类，被声明成为 final class，所有属性也都是 final 的。也由于它的不可变性，类似拼接、裁剪字符串等动作，都会产生新的 String 对象。由于字符串操作的普遍性，所以相关操作的效率往往对应用性能有明显影响。 StringBuffer 是为解决上面提到拼接产生太多中间对象的问题而提供的一个类，我们可以用 append 或者 add 方法，把字符串添加到已有序列的末尾或者指定位置。StringBuffer 本质是一个线程安全的可修改字符序列，它保证了线程安全，也随之带来了额外的性能开销，所以除非有线程安全的需要，不然还是推荐使用它的后继者，也就是 StringBuilder。 StringBuilder 是 Java 1.5 中新增的，在能力上和 StringBuffer 没有本质区别，但是它去掉了线程安全的部分，有效减小了开销，是绝大部分情况下进行字符串拼接的首选。 6、谈谈 Java 反射机制，动态代理是基于什么原理？反射机制是 Java 语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。 动态代理是一种方便运行时动态构建代理、动态处理代理方法调用的机制，很多场景都是利用类似机制做到的，比如用来包装 RPC 调用、面向切面的编程（AOP）。 实现动态代理的方式很多，比如 JDK 自身提供的动态代理，就是主要利用了上面提到的反射机制。还有其他的实现方式，比如利用传说中更高性能的字节码操作机制，类似 ASM、cglib（基于 ASM）、Javassist 等。 7、int 和 Integer 有什么区别？谈谈 Integer 的值缓存范围。int 是我们常说的整形数字，是 Java 的 8 个原始数据类型（Primitive Types，boolean、byte 、short、char、int、float、double、long）之一。Java 语言虽然号称一切都是对象，但原始数据类型是例外。 Integer 是 int 对应的包装类，它有一个 int 类型的字段存储数据，并且提供了基本操作，比如数学运算、int 和字符串之间转换等。在 Java 5 中，引入了自动装箱和自动拆箱功能（boxing&#x2F;unboxing），Java 可以根据上下文，自动进行转换，极大地简化了相关编程。 关于 Integer 的值缓存，这涉及 Java 5 中另一个改进。构建 Integer 对象的传统方式是直接调用构造器，直接 new 一个对象。但是根据实践，我们发现大部分数据操作都是集中在有限的、较小的数值范围，因而，在 Java 5 中新增了静态工厂方法 valueOf，在调用它的时候会利用一个缓存机制，带来了明显的性能改进。按照 Javadoc，这个值默认缓存是 -128 到 127 之间。 8、对比 Vector、ArrayList、LinkedList 有何区别？这三者都是实现集合框架中的 List，也就是所谓的有序集合，因此具体功能也比较近似，比如都提供按照位置进行定位、添加或者删除的操作，都提供迭代器以遍历其内容等。但因为具体的设计区别，在行为、性能、线程安全等方面，表现又有很大不同。 Vector 是 Java 早期提供的线程安全的动态数组，如果不需要线程安全，并不建议选择，毕竟同步是有额外开销的。Vector 内部是使用对象数组来保存数据，可以根据需要自动的增加容量，当数组已满时，会创建新的数组，并拷贝原有数组数据。 ArrayList 是应用更加广泛的动态数组实现，它本身不是线程安全的，所以性能要好很多。与 Vector 近似，ArrayList 也是可以根据需要调整容量，不过两者的调整逻辑有所区别，Vector 在扩容时会提高 1 倍，而 ArrayList 则是增加 50%。 LinkedList 顾名思义是 Java 提供的双向链表，所以它不需要像上面两种那样调整容量，它也不是线程安全的。 9、对比 Hashtable、HashMap、TreeMap 有什么不同？谈谈你对 HashMap 的掌握。Hashtable、HashMap、TreeMap 都是最常见的一些 Map 实现，是以键值对的形式存储和操作数据的容器类型。 Hashtable 是早期 Java 类库提供的一个哈希表实现，本身是同步的，不支持 null 键和值，由于同步导致的性能开销，所以已经很少被推荐使用。 HashMap 是应用更加广泛的哈希表实现，行为上大致上与 HashTable 一致，主要区别在于 HashMap 不是同步的，支持 null 键和值等。通常情况下，HashMap 进行 put 或者 get 操作，可以达到常数时间的性能，所以它是绝大部分利用键值对存取场景的首选，比如，实现一个用户 ID 和用户信息对应的运行时存储结构。 TreeMap 则是基于红黑树的一种提供顺序访问的 Map，和 HashMap 不同，它的 get、put、remove 之类操作都是 O（log(n)）的时间复杂度，具体顺序可以由指定的 Comparator 来决定，或者根据键的自然顺序来判断。 10、如何保证容器是线程安全的？ConcurrentHashMap 如何实现高效地线程安全？Java 提供了不同层面的线程安全支持。在传统集合框架内部，除了 Hashtable 等同步容器，还提供了所谓的同步包装器（Synchronized Wrapper），我们可以调用 Collections 工具类提供的包装方法，来获取一个同步的包装容器（如 Collections.synchronizedMap），但是它们都是利用非常粗粒度的同步方式，在高并发情况下，性能比较低下。 另外，更加普遍的选择是利用并发包提供的线程安全容器类，它提供了： 各种并发容器，比如 ConcurrentHashMap、CopyOnWriteArrayList。 各种线程安全队列（Queue&#x2F;Deque），如 ArrayBlockingQueue、SynchronousQueue。 各种有序容器的线程安全版本等。 具体保证线程安全的方式，包括有从简单的 synchronize 方式，到基于更加精细化的，比如基于分离锁实现的 ConcurrentHashMap 等并发实现等。具体选择要看开发的场景需求，总体来说，并发包内提供的容器通用场景，远优于早期的简单同步实现。 11、Java 提供了哪些 IO 方式？ NIO 如何实现多路复用？Java IO 方式有很多种，基于不同的 IO 抽象模型和交互方式，可以进行简单区分。 第一，传统的 java.io 包，它基于流模型实现，提供了我们最熟知的一些 IO 功能，比如 File 抽象、输入输出流等。交互方式是同步、阻塞的方式，也就是说，在读取输入流或者写入输出流时，在读、写动作完成之前，线程会一直阻塞在那里，它们之间的调用是可靠的线性顺序。 java.io 包的好处是代码比较简单、直观，缺点则是 IO 效率和扩展性存在局限性，容易成为应用性能的瓶颈。 很多时候，人们也把 java.net 下面提供的部分网络 API，比如 Socket、ServerSocket、HttpURLConnection 也归类到同步阻塞 IO 类库，因为网络通信同样是 IO 行为。 第二，在 Java 1.4 中引入了 NIO 框架（java.nio 包），提供了 Channel、Selector、Buffer 等新的抽象，可以构建多路复用的、同步非阻塞 IO 程序，同时提供了更接近操作系统底层的高性能数据操作方式。 第三，在 Java 7 中，NIO 有了进一步的改进，也就是 NIO 2，引入了异步非阻塞 IO 方式，也有很多人叫它 AIO（Asynchronous IO）。异步 IO 操作基于事件和回调机制，可以简单理解为，应用操作直接返回，而不会阻塞在那里，当后台处理完成，操作系统会通知相应线程进行后续工作。 12、Java 有几种文件拷贝方式？哪一种最高效？Java 有多种比较典型的文件拷贝实现方式，比如： 利用 java.io 类库，直接为源文件构建一个 FileInputStream 读取，然后再为目标文件构建一个 FileOutputStream，完成写入工作。 或者，利用 java.nio 类库提供的 transferTo 或 transferFrom 方法实现。 当然，Java 标准类库本身已经提供了几种 Files.copy 的实现。 对于 Copy 的效率，这个其实与操作系统和配置等情况相关，总体上来说，NIO transferTo&#x2F;From 的方式可能更快，因为它更能利用现代操作系统底层机制，避免不必要拷贝和上下文切换。 13、谈谈接口和抽象类有什么区别？接口和抽象类是 Java 面向对象设计的两个基础机制。 接口是对行为的抽象，它是抽象方法的集合，利用接口可以达到 API 定义和实现分离的目的。接口，不能实例化；不能包含任何非常量成员，任何 field 都是隐含着 public static final 的意义；同时，没有非静态方法实现，也就是说要么是抽象方法，要么是静态方法。Java 标准类库中，定义了非常多的接口，比如 java.util.List。 抽象类是不能实例化的类，用 abstract 关键字修饰 class，其目的主要是代码重用。除了不能实例化，形式上和一般的 Java 类并没有太大区别，可以有一个或者多个抽象方法，也可以没有抽象方法。抽象类大多用于抽取相关 Java 类的共用方法实现或者是共同成员变量，然后通过继承的方式达到代码复用的目的。Java 标准库中，比如 collection 框架，很多通用部分就被抽取成为抽象类，例如 java.util.AbstractList。 Java 类实现 interface 使用 implements 关键词，继承 abstract class 则是使用 extends 关键词，我们可以参考 Java 标准库中的 ArrayList。 14、谈谈你知道的设计模式？请手动实现单例模式，Spring 等框架中使用了哪些模式？大致按照模式的应用目标分类，设计模式可以分为创建型模式、结构型模式和行为型模式。 创建型模式，是对对象创建过程的各种问题和解决方案的总结，包括各种工厂模式（Factory、Abstract Factory）、单例模式（Singleton）、构建器模式（Builder）、原型模式（ProtoType）。 结构型模式，是针对软件设计结构的总结，关注于类、对象继承、组合方式的实践经验。常见的结构型模式，包括桥接模式（Bridge）、适配器模式（Adapter）、装饰者模式（Decorator）、代理模式（Proxy）、组合模式（Composite）、外观模式（Facade）、享元模式（Flyweight）等。 行为型模式，是从类或对象之间交互、职责划分等角度总结的模式。比较常见的行为型模式有策略模式（Strategy）、解释器模式（Interpreter）、命令模式（Command）、观察者模式（Observer）、迭代器模式（Iterator）、模板方法模式（Template Method）、访问者模式（Visitor）。 Java 进阶15、synchronized 和 ReentrantLock 有什么区别？有人说 synchronized 最慢，这话靠谱吗？synchronized 是 Java 内建的同步机制，所以也有人称其为 Intrinsic Locking，它提供了互斥的语义和可见性，当一个线程已经获取当前锁时，其他试图获取的线程只能等待或者阻塞在那里。 在 Java 5 以前，synchronized 是仅有的同步手段，在代码中， synchronized 可以用来修饰方法，也可以使用在特定的代码块儿上，本质上 synchronized 方法等同于把方法全部语句用 synchronized 块包起来。 ReentrantLock，通常翻译为再入锁，是 Java 5 提供的锁实现，它的语义和 synchronized 基本相同。再入锁通过代码直接调用 lock() 方法获取，代码书写也更加灵活。与此同时，ReentrantLock 提供了很多实用的方法，能够实现很多 synchronized 无法做到的细节控制，比如可以控制 fairness，也就是公平性，或者利用定义条件等。但是，编码中也需要注意，必须要明确调用 unlock() 方法释放，不然就会一直持有该锁。 synchronized 和 ReentrantLock 的性能不能一概而论，早期版本 synchronized 在很多场景下性能相差较大，在后续版本进行了较多改进，在低竞争场景中表现可能优于 ReentrantLock。 16、synchronized 底层如何实现？什么是锁的升级、降级？synchronized 代码块是由一对儿 monitorenter&#x2F;monitorexit 指令实现的，Monitor 对象是同步的基本实现单元。 在 Java 6 之前，Monitor 的实现完全是依靠操作系统内部的互斥锁，因为需要进行用户态到内核态的切换，所以同步操作是一个无差别的重量级操作。 现代的（Oracle）JDK 中，JVM 对此进行了大刀阔斧地改进，提供了三种不同的 Monitor 实现，也就是常说的三种不同的锁：偏斜锁（Biased Locking）、轻量级锁和重量级锁，大大改进了其性能。 所谓锁的升级、降级，就是 JVM 优化 synchronized 运行的机制，当 JVM 检测到不同的竞争状况时，会自动切换到适合的锁实现，这种切换就是锁的升级、降级。 当没有竞争出现时，默认会使用偏斜锁。JVM 会利用 CAS 操作（compare and swap），在对象头上的 Mark Word 部分设置线程 ID，以表示这个对象偏向于当前线程，所以并不涉及真正的互斥锁。这样做的假设是基于在很多应用场景中，大部分对象生命周期中最多会被一个线程锁定，使用偏斜锁可以降低无竞争开销。 如果有另外的线程试图锁定某个已经被偏斜过的对象，JVM 就需要撤销（revoke）偏斜锁，并切换到轻量级锁实现。轻量级锁依赖 CAS 操作 Mark Word 来试图获取锁，如果重试成功，就使用普通的轻量级锁；否则，进一步升级为重量级锁。 我注意到有的观点认为 Java 不会进行锁降级。实际上据我所知，锁降级确实是会发生的，当 JVM 进入安全点（SafePoint）的时候，会检查是否有闲置的 Monitor，然后试图进行降级。 17、一个线程两次调用 start() 方法会出现什么情况？谈谈线程的生命周期和状态转移。Java 的线程是不允许启动两次的，第二次调用必然会抛出 IllegalThreadStateException，这是一种运行时异常，多次调用 start 被认为是编程错误。 关于线程生命周期的不同状态，在 Java 5 以后，线程状态被明确定义在其公共内部枚举类型 java.lang.Thread.State 中，分别是： 新建（NEW），表示线程被创建出来还没真正启动的状态，可以认为它是个 Java 内部状态。 就绪（RUNNABLE），表示该线程已经在 JVM 中执行，当然由于执行需要计算资源，它可能是正在运行，也可能还在等待系统分配给它 CPU 片段，在就绪队列里面排队。 在其他一些分析中，会额外区分一种状态 RUNNING，但是从 Java API 的角度，并不能表示出来。 阻塞（BLOCKED），这个状态和我们前面两讲介绍的同步非常相关，阻塞表示线程在等待 Monitor lock。比如，线程试图通过 synchronized 去获取某个锁，但是其他线程已经独占了，那么当前线程就会处于阻塞状态。 等待（WAITING），表示正在等待其他线程采取某些操作。一个常见的场景是类似生产者消费者模式，发现任务条件尚未满足，就让当前消费者线程等待（wait），另外的生产者线程去准备任务数据，然后通过类似 notify 等动作，通知消费线程可以继续工作了。Thread.join() 也会令线程进入等待状态。 计时等待（TIMED_WAIT），其进入条件和等待状态类似，但是调用的是存在超时条件的方法，比如 wait 或 join 等方法的指定超时版本，如下面示例： 终止（TERMINATED），不管是意外退出还是正常执行结束，线程已经完成使命，终止运行，也有人把这个状态叫作死亡。 在第二次调用 start() 方法的时候，线程可能处于终止或者其他（非 NEW）状态，但是不论如何，都是不可以再次启动的。 18、什么情况下 Java 程序会产生死锁？如何定位、修复？死锁是一种特定的程序状态，在实体之间，由于循环依赖导致彼此一直处于等待之中，没有任何个体可以继续前进。死锁不仅仅是在线程之间会发生，存在资源独占的进程之间同样也可能出现死锁。通常来说，我们大多是聚焦在多线程场景中的死锁，指两个或多个线程之间，由于互相持有对方需要的锁，而永久处于阻塞的状态。 你可以利用下面的示例图理解基本的死锁问题： 定位死锁最常见的方式就是利用 jstack 等工具获取线程栈，然后定位互相之间的依赖关系，进而找到死锁。如果是比较明显的死锁，往往 jstack 等就能直接定位，类似 JConsole 甚至可以在图形界面进行有限的死锁检测。 如果程序运行时发生了死锁，绝大多数情况下都是无法在线解决的，只能重启、修正程序本身问题。所以，代码开发阶段互相审查，或者利用工具进行预防性排查，往往也是很重要的。 19、Java 并发包提供了哪些并发工具类？我们通常所说的并发包也就是 java.util.concurrent 及其子包，集中了 Java 并发的各种基础工具类，具体主要包括几个方面： 提供了比 synchronized 更加高级的各种同步结构，包括 CountDownLatch、CyclicBarrier、Semaphore 等，可以实现更加丰富的多线程操作，比如利用 Semaphore 作为资源控制器，限制同时进行工作的线程数量。 各种线程安全的容器，比如最常见的 ConcurrentHashMap、有序的 ConcurrentSkipListMap，或者通过类似快照机制，实现线程安全的动态数组 CopyOnWriteArrayList 等。 各种并发队列实现，如各种 BlockingQueue 实现，比较典型的 ArrayBlockingQueue、 SynchronousQueue 或针对特定场景的 PriorityBlockingQueue 等。 强大的 Executor 框架，可以创建各种不同类型的线程池，调度任务运行等，绝大部分情况下，不再需要自己从头实现线程池和任务调度器。 20、并发包中的 ConcurrentLinkedQueue 和 LinkedBlockingQueue 有什么区别？有时候我们把并发包下面的所有容器都习惯叫作并发容器，但是严格来讲，类似 ConcurrentLinkedQueue 这种“Concurrent*”容器，才是真正代表并发。 关于问题中它们的区别： Concurrent 类型基于 lock-free，在常见的多线程访问场景，一般可以提供较高吞吐量。 而 LinkedBlockingQueue 内部则是基于锁，并提供了 BlockingQueue 的等待性方法。 不知道你有没有注意到，java.util.concurrent 包提供的容器（Queue、List、Set）、Map，从命名上可以大概区分为 Concurrent*、CopyOnWrite和 Blocking等三类，同样是线程安全容器，可以简单认为： Concurrent 类型没有类似 CopyOnWrite 之类容器相对较重的修改开销。但是，凡事都是有代价的，Concurrent 往往提供了较低的遍历一致性。你可以这样理解所谓的弱一致性，例如，当利用迭代器遍历时，如果容器发生修改，迭代器仍然可以继续进行遍历。 与弱一致性对应的，就是我介绍过的同步容器常见的行为“fail-fast”，也就是检测到容器在遍历过程中发生了修改，则抛出 ConcurrentModificationException，不再继续遍历。 弱一致性的另外一个体现是，size 等操作准确性是有限的，未必是 100% 准确。 与此同时，读取的性能具有一定的不确定性。 21、Java 并发类库提供的线程池有哪几种？ 分别有什么特点？通常开发者都是利用 Executors 提供的通用线程池创建方法，去创建不同配置的线程池，主要区别在于不同的 ExecutorService 类型或者不同的初始参数。 Executors 目前提供了 5 种不同的线程池创建配置： newCachedThreadPool()，它是一种用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置的时间超过 60 秒，则被终止并移出缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用 SynchronousQueue 作为工作队列。 newFixedThreadPool(int nThreads)，重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列，任何时候最多有 nThreads 个工作线程是活动的。这意味着，如果任务数量超过了活动队列数目，将在工作队列中等待空闲线程出现；如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目 nThreads。 newSingleThreadExecutor()，它的特点在于工作线程数目被限制为 1，操作一个无界的工作队列，所以它保证了所有任务的都是被顺序执行，最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可以避免其改变线程数目。 newSingleThreadScheduledExecutor() 和 newScheduledThreadPool(int corePoolSize)，创建的是个 ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程。 newWorkStealingPool(int parallelism)，这是一个经常被人忽略的线程池，Java 8 才加入这个创建方法，其内部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序。 22、AtomicInteger 底层实现原理是什么？如何在自己的产品代码中应用 CAS 操作？AtomicIntger 是对 int 类型的一个封装，提供原子性的访问和更新操作，其原子性操作的实现是基于 CAS（compare-and-swap）技术。 所谓 CAS，表征的是一些列操作的集合，获取当前数值，进行一些运算，利用 CAS 指令试图进行更新。如果当前数值未变，代表没有其他线程进行并发修改，则成功更新。否则，可能出现不同的选择，要么进行重试，要么就返回一个成功或者失败的结果。 从 AtomicInteger 的内部属性可以看出，它依赖于 Unsafe 提供的一些底层能力，进行底层操作；以 volatile 的 value 字段，记录数值，以保证可见性。 具体的原子操作细节，可以参考任意一个原子更新方法，比如下面的 getAndIncrement。 Unsafe 会利用 value 字段的内存地址偏移，直接完成操作。 因为 getAndIncrement 需要返归数值，所以需要添加失败重试逻辑。 而类似 compareAndSet 这种返回 boolean 类型的函数，因为其返回值表现的就是成功与否，所以不需要重试。 CAS 是 Java 并发中所谓 lock-free 机制的基础。 23、请介绍类加载过程，什么是双亲委派模型？一般来说，我们把 Java 的类加载过程分为三个主要步骤：加载、链接、初始化，具体行为在Java 虚拟机规范里有非常详细的定义。 首先是加载阶段（Loading），它是 Java 将字节码数据从不同的数据源读取到 JVM 中，并映射为 JVM 认可的数据结构（Class 对象），这里的数据源可能是各种各样的形态，如 jar 文件、class 文件，甚至是网络数据源等；如果输入数据不是 ClassFile 的结构，则会抛出 ClassFormatError。 加载阶段是用户参与的阶段，我们可以自定义类加载器，去实现自己的类加载过程。 第二阶段是链接（Linking），这是核心的步骤，简单说是把原始的类定义信息平滑地转化入 JVM 运行的过程中。这里可进一步细分为三个步骤： 验证（Verification），这是虚拟机安全的重要保障，JVM 需要核验字节信息是符合 Java 虚拟机规范的，否则就被认为是 VerifyError，这样就防止了恶意信息或者不合规的信息危害 JVM 的运行，验证阶段有可能触发更多 class 的加载。 准备（Preparation），创建类或接口中的静态变量，并初始化静态变量的初始值。但这里的“初始化”和下面的显式初始化阶段是有区别的，侧重点在于分配所需要的内存空间，不会去执行更进一步的 JVM 指令。 解析（Resolution），在这一步会将常量池中的符号引用（symbolic reference）替换为直接引用。在Java 虚拟机规范中，详细介绍了类、接口、方法和字段等各个方面的解析。 最后是初始化阶段（initialization），这一步真正去执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先于当前类型的逻辑。 再来谈谈双亲委派模型，简单说就是当类加载器（Class-Loader）试图加载某个类型的时候，除非父加载器找不到相应类型，否则尽量将这个任务代理给当前加载器的父加载器去做。使用委派模型的目的是避免重复加载 Java 类型。 24、有哪些方法可以在运行时动态生成一个 Java 类？我们可以从常见的 Java 类来源分析，通常的开发过程是，开发者编写 Java 代码，调用 javac 编译成 class 文件，然后通过类加载机制载入 JVM，就成为应用运行时可以使用的 Java 类了。 从上面过程得到启发，其中一个直接的方式是从源码入手，可以利用 Java 程序生成一段源码，然后保存到文件等，下面就只需要解决编译问题了。 有一种笨办法，直接用 ProcessBuilder 之类启动 javac 进程，并指定上面生成的文件作为输入，进行编译。最后，再利用类加载器，在运行时加载即可。 前面的方法，本质上还是在当前程序进程之外编译的，那么还有没有不这么 low 的办法呢？ 你可以考虑使用 Java Compiler API，这是 JDK 提供的标准 API，里面提供了与 javac 对等的编译器功能，具体请参考java.compiler相关文档。 进一步思考，我们一直围绕 Java 源码编译成为 JVM 可以理解的字节码，换句话说，只要是符合 JVM 规范的字节码，不管它是如何生成的，是不是都可以被 JVM 加载呢？我们能不能直接生成相应的字节码，然后交给类加载器去加载呢？ 当然也可以，不过直接去写字节码难度太大，通常我们可以利用 Java 字节码操纵工具和类库来实现，比如在专栏第 6 讲中提到的ASM、Javassist、cglib 等。 25、谈谈 JVM 内存区域的划分，哪些区域可能发生 OutOfMemoryError？通常可以把 JVM 内存区域分为下面几个方面，其中，有的区域是以线程为单位，而有的区域则是整个 JVM 进程唯一的。 首先，程序计数器（PC，Program Counter Register）。在 JVM 规范中，每个线程都有它自己的程序计数器，并且任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。程序计数器会存储当前线程正在执行的 Java 方法的 JVM 指令地址；或者，如果是在执行本地方法，则是未指定值（undefined）。 第二，Java 虚拟机栈（Java Virtual Machine Stack），早期也叫 Java 栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧（Stack Frame），对应着一次次的 Java 方法调用。 前面谈程序计数器时，提到了当前方法；同理，在一个时间点，对应的只会有一个活动的栈帧，通常叫作当前帧，方法所在的类叫作当前类。如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，成为新的当前帧，一直到它返回结果或者执行结束。JVM 直接对 Java 栈的操作只有两个，就是对栈帧的压栈和出栈。 栈帧中存储着局部变量表、操作数（operand）栈、动态链接、方法正常退出或者异常退出的定义等。 第三，堆（Heap），它是 Java 内存管理的核心区域，用来放置 Java 对象实例，几乎所有创建的 Java 对象实例都是被直接分配在堆上。堆被所有的线程共享，在虚拟机启动时，我们指定的“Xmx”之类参数就是用来指定最大堆空间等指标。 理所当然，堆也是垃圾收集器重点照顾的区域，所以堆内空间还会被不同的垃圾收集器进行进一步的细分，最有名的就是新生代、老年代的划分。 第四，方法区（Method Area）。这也是所有线程共享的一块内存区域，用于存储所谓的元（Meta）数据，例如类结构信息，以及对应的运行时常量池、字段、方法代码等。 由于早期的 Hotspot JVM 实现，很多人习惯于将方法区称为永久代（Permanent Generation）。Oracle JDK 8 中将永久代移除，同时增加了元数据区（Metaspace）。 第五，运行时常量池（Run-Time Constant Pool），这是方法区的一部分。如果仔细分析过反编译的类文件结构，你能看到版本号、字段、方法、超类、接口等各种信息，还有一项信息就是常量池。Java 的常量池可以存放各种常量信息，不管是编译期生成的各种字面量，还是需要在运行时决定的符号引用，所以它比一般语言的符号表存储的信息更加宽泛。 第六，本地方法栈（Native Method Stack）。它和 Java 虚拟机栈是非常相似的，支持对本地方法的调用，也是每个线程都会创建一个。在 Oracle Hotspot JVM 中，本地方法栈和 Java 虚拟机栈是在同一块儿区域，这完全取决于技术实现的决定，并未在规范中强制。 26、如何监控和诊断 JVM 堆内和堆外内存使用？了解 JVM 内存的方法有很多，具体能力范围也有区别，简单总结如下： 可以使用综合性的图形化工具，如 JConsole、VisualVM（注意，从 Oracle JDK 9 开始，VisualVM 已经不再包含在 JDK 安装包中）等。这些工具具体使用起来相对比较直观，直接连接到 Java 进程，然后就可以在图形化界面里掌握内存使用情况。 以 JConsole 为例，其内存页面可以显示常见的堆内存和各种堆外部分使用状态。 也可以使用命令行工具进行运行时查询，如 jstat 和 jmap 等工具都提供了一些选项，可以查看堆、方法区等使用数据。 或者，也可以使用 jmap 等提供的命令，生成堆转储（Heap Dump）文件，然后利用 jhat 或 Eclipse MAT 等堆转储分析工具进行详细分析。 如果你使用的是 Tomcat、Weblogic 等 Java EE 服务器，这些服务器同样提供了内存管理相关的功能。 另外，从某种程度上来说，GC 日志等输出，同样包含着丰富的信息。 这里有一个相对特殊的部分，就是是堆外内存中的直接内存，前面的工具基本不适用，可以使用 JDK 自带的 Native Memory Tracking（NMT）特性，它会从 JVM 本地内存分配的角度进行解读。 27、Java 常见的垃圾收集器有哪些？实际上，垃圾收集器（GC，Garbage Collector）是和具体 JVM 实现紧密相关的，不同厂商（IBM、Oracle），不同版本的 JVM，提供的选择也不同。接下来，我来谈谈最主流的 Oracle JDK。 Serial GC，它是最古老的垃圾收集器，“Serial”体现在其收集工作是单线程的，并且在进行垃圾收集过程中，会进入臭名昭著的“Stop-The-World”状态。当然，其单线程设计也意味着精简的 GC 实现，无需维护复杂的数据结构，初始化也简单，所以一直是 Client 模式下 JVM 的默认选项。 从年代的角度，通常将其老年代实现单独称作 Serial Old，它采用了标记 - 整理（Mark-Compact）算法，区别于新生代的复制算法。 Serial GC 的对应 JVM 参数是： ParNew GC，很明显是个新生代 GC 实现，它实际是 Serial GC 的多线程版本，最常见的应用场景是配合老年代的 CMS GC 工作，下面是对应参数 CMS（Concurrent Mark Sweep） GC，基于标记 - 清除（Mark-Sweep）算法，设计目标是尽量减少停顿时间，这一点对于 Web 等反应时间敏感的应用非常重要，一直到今天，仍然有很多系统使用 CMS GC。但是，CMS 采用的标记 - 清除算法，存在着内存碎片化问题，所以难以避免在长时间运行等情况下发生 full GC，导致恶劣的停顿。另外，既然强调了并发（Concurrent），CMS 会占用更多 CPU 资源，并和用户线程争抢。 Parallel GC，在早期 JDK 8 等版本中，它是 server 模式 JVM 的默认 GC 选择，也被称作是吞吐量优先的 GC。它的算法和 Serial GC 比较相似，尽管实现要复杂的多，其特点是新生代和老年代 GC 都是并行进行的，在常见的服务器环境中更加高效。开启选项是： 另外，Parallel GC 引入了开发者友好的配置项，我们可以直接设置暂停时间或吞吐量等目标，JVM 会自动进行适应性调整，例如下面参数： G1 GC 这是一种兼顾吞吐量和停顿时间的 GC 实现，是 Oracle JDK 9 以后的默认 GC 选项。G1 可以直观的设定停顿时间的目标，相比于 CMS GC，G1 未必能做到 CMS 在最好情况下的延时停顿，但是最差情况要好很多。 G1 GC 仍然存在着年代的概念，但是其内存结构并不是简单的条带式划分，而是类似棋盘的一个个 region。Region 之间是复制算法，但整体上实际可看作是标记 - 整理（Mark-Compact）算法，可以有效地避免内存碎片，尤其是当 Java 堆非常大的时候，G1 的优势更加明显。 G1 吞吐量和停顿表现都非常不错，并且仍然在不断地完善，与此同时 CMS 已经在 JDK 9 中被标记为废弃（deprecated），所以 G1 GC 值得你深入掌握。 28、谈谈你的 GC 调优思路？谈到调优，这一定是针对特定场景、特定目的的事情， 对于 GC 调优来说，首先就需要清楚调优的目标是什么？从性能的角度看，通常关注三个方面，内存占用（footprint）、延时（latency）和吞吐量（throughput），大多数情况下调优会侧重于其中一个或者两个方面的目标，很少有情况可以兼顾三个不同的角度。当然，除了上面通常的三个方面，也可能需要考虑其他 GC 相关的场景，例如，OOM 也可能与不合理的 GC 相关参数有关；或者，应用启动速度方面的需求，GC 也会是个考虑的方面。 基本的调优思路可以总结为： 理解应用需求和问题，确定调优目标。假设，我们开发了一个应用服务，但发现偶尔会出现性能抖动，出现较长的服务停顿。评估用户可接受的响应时间和业务量，将目标简化为，希望 GC 暂停尽量控制在 200ms 以内，并且保证一定标准的吞吐量。 掌握 JVM 和 GC 的状态，定位具体的问题，确定真的有 GC 调优的必要。具体有很多方法，比如，通过 jstat 等工具查看 GC 等相关状态，可以开启 GC 日志，或者是利用操作系统提供的诊断工具等。例如，通过追踪 GC 日志，就可以查找是不是 GC 在特定时间发生了长时间的暂停，进而导致了应用响应不及时。 这里需要思考，选择的 GC 类型是否符合我们的应用特征，如果是，具体问题表现在哪里，是 Minor GC 过长，还是 Mixed GC 等出现异常停顿情况；如果不是，考虑切换到什么类型，如 CMS 和 G1 都是更侧重于低延迟的 GC 选项。 通过分析确定具体调整的参数或者软硬件配置。 验证是否达到调优目标，如果达到目标，即可以考虑结束调优；否则，重复完成分析、调整、验证这个过程。 29、Java 内存模型中的 happen-before 是什么？Happen-before 关系，是 Java 内存模型中保证多线程操作可见性的机制，也是对早期语言规范中含糊的可见性概念的一个精确定义。 它的具体表现形式，包括但远不止是我们直觉中的 synchronized、volatile、lock 操作顺序等方面，例如： 线程内执行的每个操作，都保证 happen-before 后面的操作，这就保证了基本的程序顺序规则，这是开发者在书写程序时的基本约定。 对于 volatile 变量，对它的写操作，保证 happen-before 在随后对该变量的读取操作。 对于一个锁的解锁操作，保证 happen-before 加锁操作。 对象构建完成，保证 happen-before 于 finalizer 的开始动作。 甚至是类似线程内部操作的完成，保证 happen-before 其他 Thread.join() 的线程等。 这些 happen-before 关系是存在着传递性的，如果满足 a happen-before b 和 b happen-before c，那么 a happen-before c 也成立。 前面我一直用 happen-before，而不是简单说前后，是因为它不仅仅是对执行时间的保证，也包括对内存读、写操作顺序的保证。仅仅是时钟顺序上的先后，并不能保证线程交互的可见性。 30、Java 程序运行在 Docker 等容器环境有哪些新问题？对于 Java 来说，Docker 毕竟是一个较新的环境，例如，其内存、CPU 等资源限制是通过 CGroup（Control Group）实现的，早期的 JDK 版本（8u131 之前）并不能识别这些限制，进而会导致一些基础问题： 如果未配置合适的 JVM 堆和元数据区、直接内存等参数，Java 就有可能试图使用超过容器限制的内存，最终被容器 OOM kill，或者自身发生 OOM。 错误判断了可获取的 CPU 资源，例如，Docker 限制了 CPU 的核数，JVM 就可能设置不合适的 GC 并行线程数等。 从应用打包、发布等角度出发，JDK 自身就比较大，生成的镜像就更为臃肿，当我们的镜像非常多的时候，镜像的存储等开销就比较明显了。 如果考虑到微服务、Serverless 等新的架构和场景，Java 自身的大小、内存占用、启动速度，都存在一定局限性，因为 Java 早期的优化大多是针对长时间运行的大型服务器端应用。 Java安全基础31、你了解 Java 应用开发中的注入攻击吗？注入式（Inject）攻击是一类非常常见的攻击方式，其基本特征是程序允许攻击者将不可信的动态内容注入到程序中，并将其执行，这就可能完全改变最初预计的执行过程，产生恶意效果。 下面是几种主要的注入式攻击途径，原则上提供动态执行能力的语言特性，都需要提防发生注入攻击的可能。 首先，就是最常见的 SQL 注入攻击。一个典型的场景就是 Web 系统的用户登录功能，根据用户输入的用户名和密码，我们需要去后端数据库核实信息。 假设应用逻辑是，后端程序利用界面输入动态生成类似下面的 SQL，然后让 JDBC 执行。 但是，如果我输入的 input_pwd 是类似下面的文本， 那么，拼接出的 SQL 字符串就变成了下面的条件，OR 的存在导致输入什么名字都是复合条件的。 这里只是举个简单的例子，它是利用了期望输入和可能输入之间的偏差。上面例子中，期望用户输入一个数值，但实际输入的则是 SQL 语句片段。类似场景可以利用注入的不同 SQL 语句，进行各种不同目的的攻击，甚至还可以加上“;delete xxx”之类语句，如果数据库权限控制不合理，攻击效果就可能是灾难性的。 第二，操作系统命令注入。Java 语言提供了类似 Runtime.exec(…) 的 API，可以用来执行特定命令，假设我们构建了一个应用，以输入文本作为参数，执行下面的命令： 但是如果用户输入是 “input_file_name;rm –rf &#x2F;*”，这就有可能出现问题了。当然，这只是个举例，Java 标准类库本身进行了非常多的改进，所以类似这种编程错误，未必可以真的完成攻击，但其反映的一类场景是真实存在的。 第三，XML 注入攻击。Java 核心类库提供了全面的 XML 处理、转换等各种 API，而 XML 自身是可以包含动态内容的，例如 XPATH，如果使用不当，可能导致访问恶意内容。 还有类似 LDAP 等允许动态内容的协议，都是可能利用特定命令，构造注入式攻击的，包括 XSS（Cross-site Scripting）攻击，虽然并不和 Java 直接相关，但也可能在 JSP 等动态页面中发生。 32、如何写出安全的 Java 代码？这个问题可能有点宽泛，我们可以用特定类型的安全风险为例，如拒绝服务（DoS）攻击，分析 Java 开发者需要重点考虑的点。 DoS 是一种常见的网络攻击，有人也称其为“洪水攻击”。最常见的表现是，利用大量机器发送请求，将目标网站的带宽或者其他资源耗尽，导致其无法响应正常用户的请求。 我认为，从 Java 语言的角度，更加需要重视的是程序级别的攻击，也就是利用 Java、JVM 或应用程序的瑕疵，进行低成本的 DoS 攻击，这也是想要写出安全的 Java 代码所必须考虑的。例如： 如果使用的是早期的 JDK 和 Applet 等技术，攻击者构建合法但恶劣的程序就相对容易，例如，将其线程优先级设置为最高，做一些看起来无害但空耗资源的事情。幸运的是类似技术已经逐步退出历史舞台，在 JDK 9 以后，相关模块就已经被移除。 上一讲中提到的哈希碰撞攻击，就是个典型的例子，对方可以轻易消耗系统有限的 CPU 和线程资源。从这个角度思考，类似加密、解密、图形处理等计算密集型任务，都要防范被恶意滥用，以免攻击者通过直接调用或者间接触发方式，消耗系统资源。 利用 Java 构建类似上传文件或者其他接受输入的服务，需要对消耗系统内存或存储的上限有所控制，因为我们不能将系统安全依赖于用户的合理使用。其中特别注意的是涉及解压缩功能时，就需要防范Zip bomb等特定攻击。 另外，Java 程序中需要明确释放的资源有很多种，比如文件描述符、数据库连接，甚至是再入锁，任何情况下都应该保证资源释放成功，否则即使平时能够正常运行，也可能被攻击者利用而耗尽某类资源，这也算是可能的 DoS 攻击来源。 所以可以看出，实现安全的 Java 代码，需要从功能设计到实现细节，都充分考虑可能的安全影响。 Java性能基础33、后台服务出现明显“变慢”，谈谈你的诊断思路？首先，需要对这个问题进行更加清晰的定义： 服务是突然变慢还是长时间运行后观察到变慢？类似问题是否重复出现？ “慢”的定义是什么，我能够理解是系统对其他方面的请求的反应延时变长吗? 第二，理清问题的症状，这更便于定位具体的原因，有以下一些思路： 问题可能来自于 Java 服务自身，也可能仅仅是受系统里其他服务的影响。初始判断可以先确认是否出现了意外的程序错误，例如检查应用本身的错误日志。 对于分布式系统，很多公司都会实现更加系统的日志、性能等监控系统。一些 Java 诊断工具也可以用于这个诊断，例如通过 JFR（Java Flight Recorder），监控应用是否大量出现了某种类型的异常。 如果有，那么异常可能就是个突破点。 如果没有，可以先检查系统级别的资源等情况，监控 CPU、内存等资源是否被其他进程大量占用，并且这种占用是否不符合系统正常运行状况。 监控 Java 服务自身，例如 GC 日志里面是否观察到 Full GC 等恶劣情况出现，或者是否 Minor GC 在变长等；利用 jstat 等工具，获取内存使用的统计信息也是个常用手段；利用 jstack 等工具检查是否出现死锁等。 如果还不能确定具体问题，对应用进行 Profiling 也是个办法，但因为它会对系统产生侵入性，如果不是非常必要，大多数情况下并不建议在生产系统进行。 定位了程序错误或者 JVM 配置的问题后，就可以采取相应的补救措施，然后验证是否解决，否则还需要重复上面部分过程。 34、有人说“Lambda 能让 Java 程序慢 30 倍”，你怎么看？为了让你清楚地了解这个背景，请参考下面的代码片段。在实际运行中，基于 Lambda&#x2F;Stream 的版本（lambdaMaxInteger），比传统的 for-each 版本（forEachLoopMaxInteger）慢很多。 我认为，“Lambda 能让 Java 程序慢 30 倍”这个争论实际反映了几个方面： 第一，基准测试是一个非常有效的通用手段，让我们以直观、量化的方式，判断程序在特定条件下的性能表现。 第二，基准测试必须明确定义自身的范围和目标，否则很有可能产生误导的结果。前面代码片段本身的逻辑就有瑕疵，更多的开销是源于自动装箱、拆箱（auto-boxing&#x2F;unboxing），而不是源自 Lambda 和 Stream，所以得出的初始结论是没有说服力的。 第三，虽然 Lambda&#x2F;Stream 为 Java 提供了强大的函数式编程能力，但是也需要正视其局限性： 一般来说，我们可以认为 Lambda&#x2F;Stream 提供了与传统方式接近对等的性能，但是如果对于性能非常敏感，就不能完全忽视它在特定场景的性能差异了，例如：初始化的开销。 Lambda 并不算是语法糖，而是一种新的工作机制，在首次调用时，JVM 需要为其构建CallSite实例。这意味着，如果 Java 应用启动过程引入了很多 Lambda 语句，会导致启动过程变慢。其实现特点决定了 JVM 对它的优化可能与传统方式存在差异。 增加了程序诊断等方面的复杂性，程序栈要复杂很多，Fluent 风格本身也不算是对于调试非常友好的结构，并且在可检查异常的处理方面也存在着局限性等。 35、JVM 优化 Java 代码时都做了什么？JVM 在对代码执行的优化可分为运行时（runtime）优化和即时编译器（JIT）优化。 运行时优化主要是解释执行和动态编译通用的一些机制，比如说锁机制（如偏斜锁）、内存分配机制（如 TLAB）等。除此之外，还有一些专门用于优化解释执行效率的，比如说模版解释器、内联缓存（inline cache，用于优化虚方法调用的动态绑定）。 JVM 的即时编译器优化是指将热点代码以方法为单位转换成机器码，直接运行在底层硬件之上。它采用了多种优化方式，包括静态编译器可以使用的如方法内联、逃逸分析，也包括基于程序运行 profile 的投机性优化（speculative&#x2F;optimistic optimization）。这个怎么理解呢？比如我有一条 instanceof 指令，在编译之前的执行过程中，测试对象的类一直是同一个，那么即时编译器可以假设编译之后的执行过程中还会是这一个类，并且根据这个类直接返回 instanceof 的结果。如果出现了其他类，那么就抛弃这段编译后的机器码，并且切换回解释执行。 当然，JVM 的优化方式仅仅作用在运行应用代码的时候。如果应用代码本身阻塞了，比如说并发时等待另一线程的结果，这就不在 JVM 的优化范畴啦。 Java应用开发扩展36、谈谈 MySQL 支持的事务隔离级别，以及悲观锁和乐观锁的原理和应用场景？所谓隔离级别（Isolation Level），就是在数据库事务中，为保证并发数据读写的正确性而提出的定义，它并不是 MySQL 专有的概念，而是源于ANSI&#x2F;ISO制定的SQL-92标准。 每种关系型数据库都提供了各自特色的隔离级别实现，虽然在通常的定义中是以锁为实现单元，但实际的实现千差万别。以最常见的 MySQL InnoDB 引擎为例，它是基于 MVCC（Multi-Versioning Concurrency Control）和锁的复合实现，按照隔离程度从低到高，MySQL 事务隔离级别分为四个不同层次： 读未提交（Read uncommitted），就是一个事务能够看到其他事务尚未提交的修改，这是最低的隔离水平，允许脏读出现。 读已提交（Read committed），事务能够看到的数据都是其他事务已经提交的修改，也就是保证不会看到任何中间性状态，当然脏读也不会出现。读已提交仍然是比较低级别的隔离，并不保证再次读取时能够获取同样的数据，也就是允许其他事务并发修改数据，允许不可重复读和幻象读（Phantom Read）出现。 可重复读（Repeatable reads），保证同一个事务中多次读取的数据是一致的，这是 MySQL InnoDB 引擎的默认隔离级别，但是和一些其他数据库实现不同的是，可以简单认为 MySQL 在可重复读级别不会出现幻象读。 串行化（Serializable），并发事务之间是串行化的，通常意味着读取需要获取共享读锁，更新需要获取排他写锁，如果 SQL 使用 WHERE 语句，还会获取区间锁（MySQL 以 GAP 锁形式实现，可重复读级别中默认也会使用），这是最高的隔离级别。 至于悲观锁和乐观锁，也并不是 MySQL 或者数据库中独有的概念，而是并发编程的基本概念。主要区别在于，操作共享数据时，“悲观锁”即认为数据出现冲突的可能性更大，而“乐观锁”则是认为大部分情况不会出现冲突，进而决定是否采取排他性措施。 反映到 MySQL 数据库应用开发中，悲观锁一般就是利用类似 SELECT … FOR UPDATE 这样的语句，对数据加锁，避免其他事务意外修改数据。乐观锁则与 Java 并发包中的 AtomicFieldUpdater 类似，也是利用 CAS 机制，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，来实现乐观锁需要的版本判断。 我认为前面提到的 MVCC，其本质就可以看作是种乐观锁机制，而排他性的读写锁、双阶段锁等则是悲观锁的实现。 有关它们的应用场景，你可以构建一下简化的火车余票查询和购票系统。同时查询的人可能很多，虽然具体座位票只能是卖给一个人，但余票可能很多，而且也并不能预测哪个查询者会购票，这个时候就更适合用乐观锁。 37、谈谈 Spring Bean 的生命周期和作用域？Spring Bean 生命周期比较复杂，可以分为创建和销毁两个过程。 首先，创建 Bean 会经过一系列的步骤，主要包括： 实例化 Bean 对象。 设置 Bean 属性。 如果我们通过各种 Aware 接口声明了依赖关系，则会注入 Bean 对容器基础设施层面的依赖。具体包括 BeanNameAware、BeanFactoryAware 和 ApplicationContextAware，分别会注入 Bean ID、Bean Factory 或者 ApplicationContext。 调用 BeanPostProcessor 的前置初始化方法 postProcessBeforeInitialization。 如果实现了 InitializingBean 接口，则会调用 afterPropertiesSet 方法。 调用 Bean 自身定义的 init 方法。 调用 BeanPostProcessor 的后置初始化方法 postProcessAfterInitialization。 创建过程完毕。 你可以参考下面示意图理解这个具体过程和先后顺序。 第二，Spring Bean 的销毁过程会依次调用 DisposableBean 的 destroy 方法和 Bean 自身定制的 destroy 方法。 Spring Bean 有五个作用域，其中最基础的有下面两种： Singleton，这是 Spring 的默认作用域，也就是为每个 IOC 容器创建唯一的一个 Bean 实例。 Prototype，针对每个 getBean 请求，容器都会单独创建一个 Bean 实例。 从 Bean 的特点来看，Prototype 适合有状态的 Bean，而 Singleton 则更适合无状态的情况。另外，使用 Prototype 作用域需要经过仔细思考，毕竟频繁创建和销毁 Bean 是有明显开销的。 如果是 Web 容器，则支持另外三种作用域： Request，为每个 HTTP 请求创建单独的 Bean 实例。 Session，很显然 Bean 实例的作用域是 Session 范围。 GlobalSession，用于 Portlet 容器，因为每个 Portlet 有单独的 Session，GlobalSession 提供一个全局性的 HTTP Session。 38、对比 Java 标准 NIO 类库，你知道 Netty 是如何实现更高性能的吗？单独从性能角度，Netty 在基础的 NIO 等类库之上进行了很多改进，例如： 更加优雅的 Reactor 模式实现、灵活的线程模型、利用 EventLoop 等创新性的机制，可以非常高效地管理成百上千的 Channel。 充分利用了 Java 的 Zero-Copy 机制，并且从多种角度，“斤斤计较”般的降低内存分配和回收的开销。例如，使用池化的 Direct Buffer 等技术，在提高 IO 性能的同时，减少了对象的创建和销毁；利用反射等技术直接操纵 SelectionKey，使用数组而不是 Java 容器等。 使用更多本地代码。例如，直接利用 JNI 调用 Open SSL 等方式，获得比 Java 内建 SSL 引擎更好的性能。 在通信协议、序列化等其他角度的优化。 总的来说，Netty 并没有 Java 核心类库那些强烈的通用性、跨平台等各种负担，针对性能等特定目标以及 Linux 等特定环境，采取了一些极致的优化手段。 39、谈谈常用的分布式 ID 的设计方案？Snowflake 是否受冬令时切换影响？首先，我们需要明确通常的分布式 ID 定义，基本的要求包括： 全局唯一，区别于单点系统的唯一，全局是要求分布式系统内唯一。 有序性，通常都需要保证生成的 ID 是有序递增的。例如，在数据库存储等场景中，有序 ID 便于确定数据位置，往往更加高效。 目前业界的方案很多，典型方案包括： 基于数据库自增序列的实现。这种方式优缺点都非常明显，好处是简单易用，但是在扩展性和可靠性等方面存在局限性。 基于 Twitter 早期开源的Snowflake的实现，以及相关改动方案。这是目前应用相对比较广泛的一种方式，其结构定义你可以参考下面的示意图。 整体长度通常是 64 （1 + 41 + 10+ 12 &#x3D; 64）位，适合使用 Java 语言中的 long 类型来存储。 头部是 1 位的正负标识位。 紧跟着的高位部分包含 41 位时间戳，通常使用 System.currentTimeMillis()。 后面是 10 位的 WorkerID，标准定义是 5 位数据中心 + 5 位机器 ID，组成了机器编号，以区分不同的集群节点。 最后的 12 位就是单位毫秒内可生成的序列号数目的理论极限。 Snowflake 的官方版本是基于 Scala 语言，Java 等其他语言的参考实现有很多，是一种非常简单实用的方式，具体位数的定义是可以根据分布式系统的真实场景进行修改的，并不一定要严格按照示意图中的设计。 Redis、ZooKeeper、MongoDB 等中间件，也都有各种唯一 ID 解决方案。其中一些设计也可以算作是 Snowflake 方案的变种。例如，MongoDB 的ObjectId提供了一个 12 byte（96 位）的 ID 定义，其中 32 位用于记录以秒为单位的时间，机器 ID 则为 24 位，16 位用作进程 ID，24 位随机起始的计数序列。 国内的一些大厂开源了其自身的部分分布式 ID 实现，InfoQ 就曾经介绍过微信的seqsvr，它采取了相对复杂的两层架构，并根据社交应用的数据特点进行了针对性设计，具体请参考相关代码实现。另外，百度、美团等也都有开源或者分享了不同的分布式 ID 实现，都可以进行参考。 关于第二个问题，Snowflake 是否受冬令时切换影响？ 我认为没有影响，你可以从 Snowflake 的具体算法实现寻找答案。我们知道 Snowflake 算法的 Java 实现，大都是依赖于 System.currentTimeMillis()，这个数值代表什么呢？从 Javadoc 可以看出，它是返回当前时间和 1970 年 1 月 1 号 UTC 时间相差的毫秒数，这个数值与夏 &#x2F; 冬令时并没有关系，所以并不受其影响。 "},{"date":"2022-12-04T03:08:07.695Z","url":"/2022/12/04/%E4%B8%BA%E5%95%A5%E8%A6%81%E9%87%8D%E5%86%99hashCode%E5%92%8Cequals%E6%96%B9%E6%B3%95%EF%BC%9F/","categories":[[" ",""]],"content":"[toc] 在一个长度为n（假设是10000）的线性表（假设是ArrayList）里，存放着无序的数字； 如果我们要找一个指定的数字，就不得不通过从头到尾依次遍历来查找，这样的平均查找次数是n除以2（这里是5000）。 散列表的基本概念由此可以看出，线性表的平均查找时间比较长，如果要缩短平均查找时间，我们就可以用到散列表（也叫哈希表），它的平均查找时间接近于**O(1)**。 散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。 散列函数其中存放的元素和它存放的位置，是用Hash函数来关联的。 散列函数，顾名思义，它是一个函数。我们可以把它定义成 hash(key)，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。 三点散列函数设计的基本要求： 散列函数计算得到的散列值是一个非负整数； 如果 key1 &#x3D; key2，那 hash(key1) &#x3D;&#x3D; hash(key2)； 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。 假设一个Hash函数是：x * x % 5 ，如果Hash表是一个长度为 11 的线性表。 如果我们要把 6 这个元素放到其中，那么我们先用 6 进行计算一下：6 * 6 % 5 = 1 ，它的Hash值为1，那么它应该放在下标为 1 的位置，同理：7 应该放在下标为 4 的位置。 如果我们要从散列表中找 6 这个元素，那么我们可以对这个元素进行一次Hash运算，然后再从结果中找到这个元素的索引位置。 散列冲突不过这里我们会遇到一个Hash冲突的问题，比如，我们要把 7 和 8 都放到 Hash表，根据Hash函数x * x % 5 计算，这两个数字的Hash值是一样的，也就是说，它会被放在Hash表中同一个索引，这样就导致了Hash冲突。 再好的散列函数也无法避免散列冲突。那究竟该如何解决散列冲突问题呢？我们常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。 1. 开放寻址法开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。那如何重新探测新的位置呢？ 线性探测（Linear Probing） 二次探测（Quadratic probing） 双重散列（Double hashing） 不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。 装载因子的计算公式是： 散列表的装载因子&#x3D;填入表中的元素个数&#x2F;散列表的长度 装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。 2. 链表法链表法是一种更加常用的散列冲突解决办法，在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。 下面我们采用“链表法（拉链法）”，也就是说，在这个位置，通过一个链表存放冲突数字。 hashcode 和 equals当我们用HashMap存入自定义类时，如果不重写 equals 和 hashCode 方法，得到的结果可能会和我们预期的不一样。 当我们向HashMap存放k1时，首先会调用key这个类的hashCode方法，计算它的hash值，随后把k1放入这个hash值所指引的内存位置。 但是由于key这个类没有重写equals和hashCode方法，它就会默认调用Object类的hashCode方法，而Object类里的hashCode方法返回的hash值，其实k1的内存地址，假设是1000。 这个时候，如果我们用k2去拿，它也会计算k2的hash值，随后用这个hash值到相应的位置去拿，但是k1和k2的内存地址是不一样的，因此，用k2无法拿到k1存放在HashMap中的值。 重写Key类的hashCode方法 发现输出的k1和k2的hashCode是一样的，但是k2依然无法获取k1存放在HashMap中的值。 我们重写hashCode方法之后，k1和k2确实具有了相同的hash值，k1和k2确实在Hash表中的下标是一致的，但是由于Hash函数处理Hash冲突的机制，会在k1这个位置维护一个链表，上面依次存放着k1和k2。 所以，尽管k1和k2的hash值一样，但是二者存放的地址却不相同（由于k1和k2是new出来的，所以二者的地址绝不可能一样），因为没有重写equals方法，所以默认调用Object的equals方法，二者比较的仍然是地址，所以k2无法取到k1的值。 重写Key类的equals和hashCode方法 在什么场景下重写呢？如果我们在HashMap里存放自定义的键时，我们就需要重写自定义类的hashCode和equals方法。 一般，我们在equals方法里定义判断两个对象是否相等的标准，比如，这里我们可以定义：如果两个对象的id一样，就认为这两个对象一样。 而在定义hashCode时，我们一般可以用主键的hashCode方法，比如这里我们可以用 id.hashCode() 方法来重写hashCode方法。 在面试中如何引出这个话题？ 自我介绍 我用过Java集合里的List对象以及HashMap对象，在用的时候，我需要在一定场景下重写hashCode和equals方法； 项目介绍 我在项目里用HashMap来存储日志对象，其中它的键是我们自定义的，在自定义的键中，我们需要重写hashCode和equals方法； 相关问题展开 面试官在问相关问题时，可以展开说明；比如：面试官问你：你用过Java集合中的哪些集合对象，你就可以说，我用过HashMap，并且我知道在一定场景里，我需要重写hashCode和equals方法； "},{"title":"search","date":"2022-12-03T21:14:31.000Z","url":"/search/index.html","categories":[[" ",""]]},{"title":"tags","date":"2022-12-03T21:15:52.000Z","url":"/tags/index.html","categories":[[" ",""]]}]